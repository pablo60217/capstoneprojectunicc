{"cells":[{"cell_type":"markdown","id":"82da2f31-9480-415e-98ac-4ce60a0ba163","metadata":{"tags":[],"id":"82da2f31-9480-415e-98ac-4ce60a0ba163"},"source":["# Models Development\n","### Binary and Multiclass Classification using Hugging Face, RayTune and Weights&Biases\n","\n"," **Authors:** √Ålvaro D. G√≥mez Ant√≥n, Sabah Serhir Serhir, Elisa M. Ramos Monsoriu, Lautaro Paniati Altamirano, Estefania Sol√≠s Valverde, Alba Valverde Porcar\n","\n","<br></br>\n","\n","<div style=\"text-align: right\"><i>Explaining Online Sexism: Language Models and a Mexican Perspective</i></div>\n","    \n","<div style=\"text-align: right\">A Capstone Project by United Nations International Computing Centre (<a href=\"https://www.unicc.org/\">UNICC</a>) and Universitat Polit√®cnica de Val√®ncia (<a href=\"https://www.upv.es/es\">UPV</a>) </div>\n","\n","---"]},{"cell_type":"markdown","id":"63d30cec-d92b-405d-b39a-487e28c4a5b4","metadata":{"id":"63d30cec-d92b-405d-b39a-487e28c4a5b4"},"source":["In this notebook, we embark on a journey to detect and classify sexism content in Spanish tweets. With the rise of social media, online sexism has become a pressing issue that requires effective monitoring and intervention. Leveraging the power of deep learning and language models, we aim to develop a robust classification system that can accurately identify and categorize sexist content in Spanish text.\n","\n","To tackle our objectives, we adopt a fine-tuning approach using a pretrained large language model (LLM). However, we take a unique path by exploring two distinct training strategies. The first approach involves utilizing only the original Spanish data, while the second incorporates both the original and translated data.\n","\n","The incorporation of translated data serves a crucial purpose ‚Äì to evaluate the impact of language translation on the classification task. Deep learning models, including LLMs, often exhibit improved performance with larger training datasets. However, preserving the original meaning of the text becomes a challenge during translation. Conventional translation tools may struggle to retain the intended meaning, potentially affecting the performance of our models.\n","\n","Thus, we set out to investigate whether large language models, such as GPT-3.5, can effectively translate text while maintaining its meaning and valuable information. If the results obtained using the translated data are equal to or better than those achieved solely with Spanish data, it would signify the capacity of these models to preserve meaning during translation. Such a discovery would be significant, as it suggests a promising solution to overcome data scarcity in specific-language natural language processing (NLP) problems. Currently, languages other than widely used ones like English often lack sufficient data, limiting the full potential of artificial intelligence and machine learning in these contexts.\n","\n","Conversely, if the performance using translated data is worse, it would indicate that large language models have not yet reached their full efficiency in overcoming language barriers. Understanding these outcomes will provide valuable insights into the capabilities and limitations of language models in addressing the challenges of online sexism in Spanish.\n","\n","Throughout this notebook, we will guide you through the steps of training and fine-tuning our models using the ü§ó Hugging Face ecosystem, analyzing their performance using both aforementioned approaches, optimizing hyperparameters with RayTune, and evaluating the results using the Weights&Biases platform. By the end, we aim to contribute to the development of effective tools for combating online sexism, promoting safer digital spaces, and fostering inclusive communities."]},{"cell_type":"markdown","id":"6830e80c-7d3a-4ed9-9aca-5e4985f76100","metadata":{"id":"6830e80c-7d3a-4ed9-9aca-5e4985f76100"},"source":["**Requirements**"]},{"cell_type":"code","execution_count":1,"id":"1f72fe20-b727-47fb-bb0a-8cdc20a602bb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f72fe20-b727-47fb-bb0a-8cdc20a602bb","executionInfo":{"status":"ok","timestamp":1751612215874,"user_tz":-120,"elapsed":58370,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}},"outputId":"1259ddf7-a345-4494-f489-c3f3da21f271"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.41.0 in /usr/local/lib/python3.11/dist-packages (4.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (0.33.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (2025.6.15)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.4)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0.dev0)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n","Collecting git+https://github.com/huggingface/accelerate\n","  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-ecafi6ks\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-ecafi6ks\n","  Resolved https://github.com/huggingface/accelerate to commit 07ce74868cf0197a43dfa7aaf120384ec5a4afd8\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (2.6.0+cu124)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (0.33.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.9.0.dev0) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (2025.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (1.1.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.9.0.dev0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.9.0.dev0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.9.0.dev0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.9.0.dev0) (2025.6.15)\n","Requirement already satisfied: ray[tune] in /usr/local/lib/python3.11/dist-packages (2.47.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (8.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (3.18.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (4.24.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (24.2)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (5.29.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.32.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.2.2)\n","Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.6.4)\n","Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (18.1.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2025.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=1.9->ray[tune]) (2.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.26.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2025.6.15)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.17.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray[tune]) (4.14.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.20.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n","Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"]}],"source":["!pip install --upgrade transformers==4.41.0\n","!pip install datasets\n","!pip install evaluate\n","!pip install accelerate\n","!pip install git+https://github.com/huggingface/accelerate\n","!pip install 'ray[tune]'\n","!pip install wandb\n"]},{"cell_type":"markdown","id":"6afa290a-2005-47cf-9afe-f8da62bf9eab","metadata":{"id":"6afa290a-2005-47cf-9afe-f8da62bf9eab"},"source":["## The Data"]},{"cell_type":"markdown","id":"32a92c33-4698-40f4-b658-7fcc65f27797","metadata":{"id":"32a92c33-4698-40f4-b658-7fcc65f27797"},"source":["Our dataset consists of labeled tweets, differentiating between sexism and non-sexism, with additional categorization of the specific types of sexism displayed. It encompasses original Spanish tweets collected from diverse sources, as well as translated tweets that were originally in English and subsequently translated to Mexican Spanish using GPT-3.5. Mexican Spanish because the aim of this modelos is to be used in the MExican scenario. For a more comprehensive understanding of the data preparation steps, we encourage you to refer to the \"1-data-preparation.ipynb\" notebook."]},{"cell_type":"code","execution_count":2,"id":"5b2ee402-bec0-4108-a5c5-3b5aa88a6bc0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":912},"id":"5b2ee402-bec0-4108-a5c5-3b5aa88a6bc0","executionInfo":{"status":"ok","timestamp":1751612217005,"user_tz":-120,"elapsed":1077,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}},"outputId":"6a0b632a-0550-4704-a5cc-fa5361f0436d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2-1417784026.py:9: DtypeWarning: Columns (8,9,10,11,12,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv(file_path)\n"]},{"output_type":"execute_result","data":{"text/plain":["                 source_dataset  target_column subcategory_combined  \\\n","0      edos_labelled_aggregated            0.0                  NaN   \n","1      edos_labelled_aggregated            0.0                  NaN   \n","2      edos_labelled_aggregated            0.0                  NaN   \n","3      edos_labelled_aggregated            0.0                  NaN   \n","4      edos_labelled_aggregated            0.0                  NaN   \n","...                         ...            ...                  ...   \n","53106        EXIST2021_training            0.0                  NaN   \n","53107        EXIST2021_training            0.0                  NaN   \n","53108        EXIST2021_training            0.0                  NaN   \n","53109        EXIST2021_training            1.0                  NaN   \n","53110        EXIST2021_training            1.0                  NaN   \n","\n","                                                    text  \\\n","0      In Nigeria, if you rape a woman, the men rape ...   \n","1                                Then, she's a keeper. üòâ   \n","2      This is like the Metallica video where the poo...   \n","3                                                 woman?   \n","4                         I bet she wished she had a gun   \n","...                                                  ...   \n","53106  Estamos igual sin pareja, pero puedes besar a ...   \n","53107                          2020 hijo de re mil putas   \n","53108  SEGURAMENTE ESTA CHICA NO COBRA EL DINERO QUE ...   \n","53109     @safetyaitana mi madre dice q va fea y i agree   \n","53110  ¬øEn vuestras casas tambi√©n ten√©is esa tradici√≥...   \n","\n","                                            text_english      id  \\\n","0      In Nigeria, if you rape a woman, the men rape ...     NaN   \n","1                                Then, she's a keeper. üòâ     NaN   \n","2      This is like the Metallica video where the poo...     NaN   \n","3                                                 woman?     NaN   \n","4                         I bet she wished she had a gun     NaN   \n","...                                                  ...     ...   \n","53106  We're the same without a partner, but you can ...  6973.0   \n","53107                                2020 son of a bitch  6974.0   \n","53108  SURELY THIS GIRL DOESN'T GET PAID THE MONEY SH...  6975.0   \n","53109  @safetyaitana my mother says she looks ugly an...  6976.0   \n","53110  Do you also have that shitty tradition in your...  6977.0   \n","\n","      subcategory_general subcategory_specific                 rewire_id  \\\n","0                     NaN                  NaN   sexism2022_english-9609   \n","1                     NaN                  NaN  sexism2022_english-16993   \n","2                     NaN                  NaN  sexism2022_english-13149   \n","3                     NaN                  NaN  sexism2022_english-13021   \n","4                     NaN                  NaN    sexism2022_english-966   \n","...                   ...                  ...                       ...   \n","53106                 NaN                  NaN                       NaN   \n","53107                 NaN                  NaN                       NaN   \n","53108                 NaN                  NaN                       NaN   \n","53109                 NaN                  NaN                       NaN   \n","53110                 NaN                  NaN                       NaN   \n","\n","      label_sexist  ... annotator  HS  TR  AG  label  test_case   source  \\\n","0       not sexist  ...       NaN NaN NaN NaN    NaN        NaN      NaN   \n","1       not sexist  ...       NaN NaN NaN NaN    NaN        NaN      NaN   \n","2       not sexist  ...       NaN NaN NaN NaN    NaN        NaN      NaN   \n","3       not sexist  ...       NaN NaN NaN NaN    NaN        NaN      NaN   \n","4       not sexist  ...       NaN NaN NaN NaN    NaN        NaN      NaN   \n","...            ...  ...       ...  ..  ..  ..    ...        ...      ...   \n","53106          NaN  ...       NaN NaN NaN NaN    NaN  EXIST2021  twitter   \n","53107          NaN  ...       NaN NaN NaN NaN    NaN  EXIST2021  twitter   \n","53108          NaN  ...       NaN NaN NaN NaN    NaN  EXIST2021  twitter   \n","53109          NaN  ...       NaN NaN NaN NaN    NaN  EXIST2021  twitter   \n","53110          NaN  ...       NaN NaN NaN NaN    NaN  EXIST2021  twitter   \n","\n","       language       task1                   task2  \n","0           NaN         NaN                     NaN  \n","1           NaN         NaN                     NaN  \n","2           NaN         NaN                     NaN  \n","3           NaN         NaN                     NaN  \n","4           NaN         NaN                     NaN  \n","...         ...         ...                     ...  \n","53106        es  non-sexist              non-sexist  \n","53107        es  non-sexist              non-sexist  \n","53108        es  non-sexist              non-sexist  \n","53109        es      sexist         objectification  \n","53110        es      sexist  stereotyping-dominance  \n","\n","[53111 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-f10b5aa7-1677-4309-9f35-7c10756de377\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_dataset</th>\n","      <th>target_column</th>\n","      <th>subcategory_combined</th>\n","      <th>text</th>\n","      <th>text_english</th>\n","      <th>id</th>\n","      <th>subcategory_general</th>\n","      <th>subcategory_specific</th>\n","      <th>rewire_id</th>\n","      <th>label_sexist</th>\n","      <th>...</th>\n","      <th>annotator</th>\n","      <th>HS</th>\n","      <th>TR</th>\n","      <th>AG</th>\n","      <th>label</th>\n","      <th>test_case</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>edos_labelled_aggregated</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n","      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sexism2022_english-9609</td>\n","      <td>not sexist</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>edos_labelled_aggregated</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>Then, she's a keeper. üòâ</td>\n","      <td>Then, she's a keeper. üòâ</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sexism2022_english-16993</td>\n","      <td>not sexist</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>edos_labelled_aggregated</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>This is like the Metallica video where the poo...</td>\n","      <td>This is like the Metallica video where the poo...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sexism2022_english-13149</td>\n","      <td>not sexist</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>edos_labelled_aggregated</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>woman?</td>\n","      <td>woman?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sexism2022_english-13021</td>\n","      <td>not sexist</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>edos_labelled_aggregated</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>I bet she wished she had a gun</td>\n","      <td>I bet she wished she had a gun</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>sexism2022_english-966</td>\n","      <td>not sexist</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>53106</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>Estamos igual sin pareja, pero puedes besar a ...</td>\n","      <td>We're the same without a partner, but you can ...</td>\n","      <td>6973.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>53107</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>2020 hijo de re mil putas</td>\n","      <td>2020 son of a bitch</td>\n","      <td>6974.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>53108</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>SEGURAMENTE ESTA CHICA NO COBRA EL DINERO QUE ...</td>\n","      <td>SURELY THIS GIRL DOESN'T GET PAID THE MONEY SH...</td>\n","      <td>6975.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>53109</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>@safetyaitana mi madre dice q va fea y i agree</td>\n","      <td>@safetyaitana my mother says she looks ugly an...</td>\n","      <td>6976.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","    </tr>\n","    <tr>\n","      <th>53110</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>¬øEn vuestras casas tambi√©n ten√©is esa tradici√≥...</td>\n","      <td>Do you also have that shitty tradition in your...</td>\n","      <td>6977.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>stereotyping-dominance</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>53111 rows √ó 24 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f10b5aa7-1677-4309-9f35-7c10756de377')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f10b5aa7-1677-4309-9f35-7c10756de377 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f10b5aa7-1677-4309-9f35-7c10756de377');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-829ddd9e-1343-4387-8fa9-a6cc9ece658f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-829ddd9e-1343-4387-8fa9-a6cc9ece658f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-829ddd9e-1343-4387-8fa9-a6cc9ece658f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_49a7d7b4-db5b-4866-b4f8-f03dc9804379\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_49a7d7b4-db5b-4866-b4f8-f03dc9804379 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":2}],"source":["import pandas as pd\n","#data = pd.read_csv(\"../data/transformed/gold_data.tsv\", sep=\"\\t\")\n","#file_path = r\"C:\\Users\\juanm\\OneDrive\\Documentos\\@ Maestria Ie\\Term 3 - Electives\\CapstoneProject\\UPV-capstone-Women-Safter-Online-1\\Latam_Bert\\traducido_dataset_unificado.csv\"\n","\n","file_path = \"/content/traducido_dataset_unificado.csv\"\n","\n","\n","# Load the DataFrame\n","data = pd.read_csv(file_path)\n","\n","data"]},{"cell_type":"markdown","id":"e2bc5af3-fed2-4850-ac39-66fcd7625d3d","metadata":{"tags":[],"id":"e2bc5af3-fed2-4850-ac39-66fcd7625d3d"},"source":["### Initial Preparation"]},{"cell_type":"markdown","id":"9ee83fef-8abf-4c56-bb72-39b8786a75ad","metadata":{"id":"9ee83fef-8abf-4c56-bb72-39b8786a75ad"},"source":["For the initial training approach, we worked with a Spanish dataset consisting of 11,479 tweets. The tweets were labeled as either sexist or non-sexist, with a quite balanced distribution of approximately 46% and 54% respectively. In the second training approach, which involved incorporating translations, a larger dataset of 58,399 tweets was utilized. However, this dataset exhibited an imbalanced label distribution, with approximately 68.5% classified as non-sexist and 31.5% classified as sexist. To ensure a fair comparison between the two approaches, we needed to address this imbalance.\n","\n","We decided to adjust the positive class ratio in the translated dataset to match that of the Spanish dataset, which was 45%. To achieve this, we employed a technique called undersampling. By randomly discarding instances from the majority class (non-sexist), we reduced its percentage in the dataset, resulting in a more balanced distribution. This adjusted dataset served as the final training data for our models."]},{"cell_type":"code","execution_count":3,"id":"be22c357-9d41-44dc-a705-993b63a68b0a","metadata":{"id":"be22c357-9d41-44dc-a705-993b63a68b0a","executionInfo":{"status":"ok","timestamp":1751612217013,"user_tz":-120,"elapsed":16,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["def balance_data_with_undersampling(df, positive_ratio) -> pd.DataFrame:\n","    \"\"\"\n","    Balances the data by performing undersampling on the majority class.\n","\n","    This function takes a DataFrame containing labeled data and performs undersampling\n","    on the majority class to balance the distribution of positive and negative instances.\n","    It ensures that the positive-to-negative ratio in the resulting dataset is not higher\n","    than the specified positive ratio.\n","\n","    Args:\n","        - df (pandas.DataFrame): The DataFrame containing the labeled data.\n","        - positive_ratio (float): The desired positive-to-negative ratio after balancing.\n","\n","    Returns:\n","        pandas.DataFrame: The balanced dataset after performing undersampling.\n","\n","    \"\"\"\n","    df = df.copy()\n","\n","    # Calculate the actual positive count and ratio in the data frame\n","    actual_pos_count = df.label.sum()\n","    actual_pos_ratio = actual_pos_count / len(df)\n","\n","    # Check if the actual positive ratio is higher than the desired positive ratio\n","    _changed = False\n","    if actual_pos_ratio > positive_ratio:\n","        # Invert the labels if the actual positive ratio is higher\n","        df.label = df.label.apply(lambda x: not x)\n","        actual_pos_count = len(df) - actual_pos_count\n","        actual_pos_ratio = 1 - actual_pos_ratio\n","        positive_ratio = 1 - positive_ratio\n","        _changed = True\n","\n","    # Get all the positive instances\n","    pos_instances = df.loc[df.label == 1, :]\n","\n","    # Undersample the negative class\n","    neg_instances_allowed = int(actual_pos_count * ((1 - positive_ratio) / positive_ratio))\n","    neg_instances = df.loc[df.label == 0, :].sample(n=neg_instances_allowed)\n","\n","    # Concatenate positive and negative instances to create a balanced dataset\n","    balanced_data = pd.concat([pos_instances, neg_instances], axis=0)\n","\n","    # Revert the label inversion if performed earlier\n","    if _changed:\n","        balanced_data.label = balanced_data.label.apply(lambda x: not x).astype(int)\n","\n","    return balanced_data"]},{"cell_type":"markdown","id":"ac8e08ea-bd43-42ed-9736-c5530b0296fd","metadata":{"id":"ac8e08ea-bd43-42ed-9736-c5530b0296fd"},"source":["### Adapting to ü§ó Hugging Face Ecosystem"]},{"cell_type":"markdown","id":"3f601c01-1792-48e6-a957-d90108290fbd","metadata":{"id":"3f601c01-1792-48e6-a957-d90108290fbd"},"source":["To adapt our workflow to the ü§ó Hugging Face ecosystem, we introduced the `SexismDataset` object. This object serves as a versatile solution for efficient data preparation and tokenization in both the detection and classification tasks. It accepts a filepath or DataFrame as input, along with the task name (detection or classification) and an optional model checkpoint for tokenization.\n","\n","The SexismDataset object streamlines the data preparation process by loading the data and performing necessary preprocessing steps. For instance, it can rename columns to match the requirements of the task at hand (e.g., \"text\" and \"label\" for text classification fine-tuning). Additionally, it applies undersampling to balance the dataset for the detection task and performs label encoding for the classification task. The dataset is then split into training, validation, and test sets in a ratio of 75:15:10, respectively.\n","\n","To facilitate tokenization, the `SexismDataset` object leverages the tokenizers provided by ü§ó Hugging Face. It tokenizes the text data, taking into account a maximum sequence length of 512 tokens, and stores the tokenized representations of the dataset.\n","\n","By encapsulating the data preparation and tokenization processes within the `SexismDataset` object, we ensure consistency and modularity in our workflow. This approach allows us to handle the specific requirements of the detection and classification tasks while sharing common functionality. Furthermore, the object provides a convenient interface for accessing the tokenized dataset and calculating evaluation metrics for both tasks."]},{"cell_type":"code","execution_count":4,"id":"26812388-008f-4191-b363-53b9131edaa0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26812388-008f-4191-b363-53b9131edaa0","executionInfo":{"status":"ok","timestamp":1751612232492,"user_tz":-120,"elapsed":15476,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}},"outputId":"aa28ea7e-a56d-49de-d94f-bc18748a27c1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["import os\n","import json\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","from datasets import Dataset, DatasetDict\n","from transformers import AutoTokenizer\n","import evaluate\n","\n","from typing import List, Dict, Tuple, Union, Callable, Optional\n","\n","f1_metric = evaluate.load(\"f1\")\n","accuracy_metric = evaluate.load(\"accuracy\")\n","precision_metric = evaluate.load(\"precision\")\n","recall_metric = evaluate.load(\"recall\")\n","\n","class SexismDataset:\n","    def __init__(\n","            self,\n","            filepath_or_df: Union[str, pd.DataFrame],\n","            task_name: str,\n","            model_checkpoint: Optional[str] = None,\n","            seed: int = 1234,\n","            max_instances: Optional[Union[int, float]] = None\n","        ):\n","        \"\"\"\n","        Initialize the SexismDataset object.\n","\n","        Parameters:\n","            - filepath_or_df (Union[str, pd.DataFrame]): Path to a CSV/TSV file or a pandas DataFrame containing the dataset.\n","            - task_name (str): Task name, either \"detection\" or \"classification\".\n","            - model_checkpoint (Optional[str]): Model checkpoint for tokenization.\n","            - seed (int): Random seed for reproducibility.\n","            - max_instances (Optional[Union[int, float]]): Maximum number of instances to include in the dataset.\n","        \"\"\"\n","        self.seed = seed\n","        self.task = task_name\n","        self._max_instances = max_instances\n","\n","        if isinstance(filepath_or_df, str):\n","            # Load dataset from a file\n","            self._df = pd.read_csv(\n","                filepath_or_buffer=filepath_or_df,\n","                sep=\"\\t\" if filepath_or_df.endswith(\".tsv\") else \";\"\n","            )\n","        elif isinstance(filepath_or_df, pd.DataFrame):\n","            # Use the provided DataFrame\n","            self._df = filepath_or_df.copy()\n","\n","        self._df.rename(\n","            columns={\"sexist\" if self.task == \"detection\" else \"type\": \"label\"},\n","            inplace=True\n","        )\n","\n","        if max_instances:\n","            # Perform undersampling if max_instances is specified\n","            self._df = self.sample_df(max_instances)\n","\n","        self.num_labels = len(self._df.label.unique())\n","\n","        self.dataset = self._prepare_dataset()\n","\n","        if model_checkpoint:\n","            # Tokenize the dataset if a model checkpoint is provided\n","            print(\"Tokenizing dataset...\")\n","            self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n","            self.tokenized = self.dataset.map(self._tokenize, batched=True)\n","\n","    def _make_dataset_from_pandas(self, data: Union[pd.DataFrame,dict]):\n","        \"\"\"\n","        Convert a pandas DataFrame or dictionary of DataFrames to a Hugging Face Dataset object.\n","\n","        Parameters:\n","            - data (Union[pd.DataFrame, dict]): Input data to convert.\n","\n","        Returns:\n","            Dataset: Hugging Face Dataset object.\n","        \"\"\"\n","        if isinstance(data, pd.DataFrame):\n","            # Convert single DataFrame\n","            return Dataset.from_pandas(data)\n","        elif isinstance(data, dict):\n","            # Convert dictionary of DataFrames\n","            ds_dict = DatasetDict()\n","            for split, df in data.items():\n","                ds_dict[split] = Dataset.from_pandas(df)\n","            return ds_dict\n","\n","    def _prepare_dataset(self):\n","        \"\"\"\n","        Prepare the dataset for training.\n","\n","        Returns:\n","            Dataset: Prepared dataset.\n","        \"\"\"\n","        data = self._df.loc[:, [\"text\", \"label\"]]\n","\n","        if self.task == \"detection\":\n","            # Perform label balancing (undersampling) for detection task\n","            data = balance_data_with_undersampling(data, positive_ratio=0.45)\n","\n","        elif self.task == \"classification\":\n","            # Perform label encoding for classification task\n","            self.le = LabelEncoder()\n","            data.label = self.le.fit_transform(data.label.to_list())\n","\n","        # Split the data into training, validation, and test sets\n","        train_data, eval_data = train_test_split(data,\n","                                                 test_size=0.25,\n","                                                 stratify=data.label,\n","                                                 shuffle=True,\n","                                                 random_state=self.seed)\n","\n","        # Split the evaluation data into validation and test sets\n","        val_data, test_data = train_test_split(eval_data,\n","                                               test_size=0.1/0.25,\n","                                               stratify=eval_data.label,\n","                                               random_state=self.seed)\n","\n","        dfs = {\"train\": train_data, \"validation\": val_data, \"test\": test_data}\n","        ds = self._make_dataset_from_pandas(dfs).select_columns([\"text\", \"label\"])\n","        if \"__index_level_0__\" in ds.column_names:\n","            ds.remove_columns(\"__index_level_0__\")\n","        return ds\n","\n","    def _tokenize(self, examples):\n","        \"\"\"\n","        Tokenize input examples using the specified tokenizer.\n","\n","        Parameters:\n","            - examples: Input examples to be tokenized.\n","\n","        Returns:\n","            Dict: Tokenized examples.\n","        \"\"\"\n","        return self.tokenizer(examples[\"text\"],\n","                              padding='max_length',\n","                              max_length = 512,\n","                              truncation = True)\n","\n","    def sample_df(self, n_or_perc):\n","        \"\"\"\n","        Sample a fraction or a specific number of instances from the dataset.\n","\n","        Parameters:\n","            - n_or_perc: Number of instances or percentage to sample.\n","\n","        Returns:\n","            pd.DataFrame: Sampled dataset.\n","        \"\"\"\n","        if n_or_perc < 0:\n","            raise ValueError(\"'n_or_perc' must be positive\")\n","        if n_or_perc > 1:\n","            n_or_perc /= len(self._df)\n","        data, _ =  train_test_split(self._df,\n","                                    train_size=n_or_perc,\n","                                    stratify=self._df.label,\n","                                    shuffle=True,\n","                                    random_state=self.seed)\n","        return data\n","\n","    def build_compute_metrics(self):\n","        \"\"\"\n","        Build a compute_metrics function for evaluating the model.\n","\n","        Returns:\n","            function: Compute metrics function.\n","        \"\"\"\n","        def compute_metrics(eval_pred):\n","            logits, labels = eval_pred\n","            predictions = np.argmax(logits, axis=1)\n","            compute_kwargs = {\n","                \"predictions\": predictions,\n","                \"references\": labels\n","            }\n","            average = \"binary\" if self.task == \"detection\" else \"macro\"\n","            return {\n","                **accuracy_metric.compute(**compute_kwargs),\n","                **f1_metric.compute(**compute_kwargs, average=average),\n","                **precision_metric.compute(**compute_kwargs, average=average),\n","                **recall_metric.compute(**compute_kwargs, average=average)\n","            }\n","        return compute_metrics\n","\n","    def __getitem__(self, key):\n","        \"\"\"\n","        Get the dataset or tokenized examples.\n","\n","        Parameters:\n","            - key: Key to access dataset or tokenized examples.\n","\n","        Returns:\n","            Dataset or Tokenized: Dataset or tokenized examples.\n","        \"\"\"\n","        if key == \"dataset\":\n","            return self.dataset\n","        elif key == \"tokenized\":\n","            return self.tokenized\n","        else:\n","            raise KeyError(f\"{key} not supported. Must be 'dataset' or 'tokenized'\")"]},{"cell_type":"markdown","id":"a2a21f33-b5e9-4e6c-9cc0-9168e4b3517b","metadata":{"id":"a2a21f33-b5e9-4e6c-9cc0-9168e4b3517b"},"source":["With the data prepared and tokenized using the `SexismDataset` object, we are almost ready to proceed with training and evaluating our models."]},{"cell_type":"markdown","id":"330492e4-f111-4de6-93de-22c0a826f29f","metadata":{"id":"330492e4-f111-4de6-93de-22c0a826f29f"},"source":["## The Base Model"]},{"cell_type":"markdown","id":"15140985-6026-4f90-bad6-237e45a29b61","metadata":{"id":"15140985-6026-4f90-bad6-237e45a29b61"},"source":["For our project, we selected [\"roberta-base-bne\"](https://huggingface.co/PlanTL-GOB-ES/roberta-base-bne) as our base model. This is part of the [Spanish Government's Language Technology Plan](https://plantl.mineco.gob.es/tecnologias-lenguaje/Paginas/tecnologias-lenguaje.aspx) and is specifically designed for the Spanish language. It is built upon the RoBERTa base model ([ref.](https://arxiv.org/abs/1907.11692)), a highly acclaimed transformer-based masked language model.\n","\n","The \"roberta-base-bne\" model has undergone extensive pre-training using a vast Spanish corpus, which comprises 570GB of clean and deduplicated text, was meticulously compiled from web crawlings conducted by the National Library of Spain ([Biblioteca Nacional de Espa√±a](https://www.bne.es/en/Inicio/index.html)) between 2009 and 2019. This rich and diverse dataset provides a solid foundation for the model's understanding of the Spanish language .\n","\n","We specifically chose the \"roberta-base-bne\" model due to its exceptional performance in various Spanish NLP tasks. RoBERTa-based models have consistently achieved state-of-the-art results, demonstrating their effectiveness in capturing the intricacies and nuances of the Spanish language ([ref.](http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6405/3820)).\n","\n","To acquire and fine-tune our models, we relied on the powerful [ü§ó HuggingFace](https://huggingface.co/) Transformers library."]},{"cell_type":"code","execution_count":5,"id":"0c7c29c0-5bc4-4cc2-bad0-071acce7b09c","metadata":{"id":"0c7c29c0-5bc4-4cc2-bad0-071acce7b09c","executionInfo":{"status":"ok","timestamp":1751612232506,"user_tz":-120,"elapsed":5,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["MODEL_CHECKPOINT = \"PlanTL-GOB-ES/roberta-base-bne\""]},{"cell_type":"markdown","id":"33bfccd5-be66-4b8a-9d47-506e30998d81","metadata":{"id":"33bfccd5-be66-4b8a-9d47-506e30998d81"},"source":["With the data prepared and tokenized using the `SexismDataset` object, we are now equipped with the necessary components to proceed with the fine-tuning, training, and evaluation of our models. The \"roberta-base-bne\" model, with its deep understanding of the Spanish language, will serve as the foundation for our journey into detecting and classifying online sexism in Spanish tweets."]},{"cell_type":"markdown","id":"7ce10961-34cc-4504-be2f-1da26ecf7a49","metadata":{"tags":[],"id":"7ce10961-34cc-4504-be2f-1da26ecf7a49"},"source":["## Josefina - Sexism Detection"]},{"cell_type":"markdown","id":"1c3c64dd-064f-4141-8b82-8d06d9f1f3bb","metadata":{"id":"1c3c64dd-064f-4141-8b82-8d06d9f1f3bb"},"source":["Now, let's delve into the training stage of the notebook, where we develop the models. Our primary objective is sexism detection, and to accomplish this, we introduce Josefina, a robust NLP model meticulously crafted to combat sexism in text. Harnessing the power of advanced language processing techniques, Josefina excels at identifying and addressing gender bias, actively advocating for fairness and inclusivity. Through its meticulous analysis of language patterns, Josefina skillfully uncovers even the most nuanced instances of sexism, contributing significantly to the creation of a more respectful and equitable online environment.."]},{"cell_type":"markdown","id":"4c26e55d-210e-41b2-ae0d-b2b2ed557174","metadata":{"id":"4c26e55d-210e-41b2-ae0d-b2b2ed557174"},"source":["### Training with Original Spanish data"]},{"cell_type":"markdown","id":"4e5f5976-cbb1-44c5-855d-336e4302bf4a","metadata":{"id":"4e5f5976-cbb1-44c5-855d-336e4302bf4a"},"source":["In this subsection, we focus on training our model using the original Spanish dataset. The dataset, specifically curated for this project, consists of tweets written in Spanish. We begin by filtering the data to include only the Spanish language using the 'language' attribute. This refined dataset is then passed into the SexismDataset object, specifically configured for the 'detection' task and using the designated model checkpoint."]},{"cell_type":"code","execution_count":6,"id":"9581633e","metadata":{"id":"9581633e","executionInfo":{"status":"ok","timestamp":1751612232516,"user_tz":-120,"elapsed":4,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["data = data.rename(columns={'label': 'original_label', 'target_column': 'label'})"]},{"cell_type":"code","execution_count":7,"id":"be439b64","metadata":{"id":"be439b64","executionInfo":{"status":"ok","timestamp":1751612232566,"user_tz":-120,"elapsed":9,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["data_es = data.query(\"language == 'es'\")\n"]},{"cell_type":"code","execution_count":8,"id":"cb39697c","metadata":{"id":"cb39697c","executionInfo":{"status":"ok","timestamp":1751612232580,"user_tz":-120,"elapsed":10,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["data_es = data_es.dropna(subset=['label'])\n"]},{"cell_type":"code","execution_count":9,"id":"ad39464b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"id":"ad39464b","executionInfo":{"status":"ok","timestamp":1751612232638,"user_tz":-120,"elapsed":53,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}},"outputId":"4274bb1b-ca26-408e-abd0-a473b1f22894"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           source_dataset  label subcategory_combined  \\\n","49598  EXIST2021_training    1.0                  NaN   \n","49599  EXIST2021_training    1.0                  NaN   \n","49600  EXIST2021_training    0.0                  NaN   \n","49601  EXIST2021_training    0.0                  NaN   \n","49602  EXIST2021_training    0.0                  NaN   \n","...                   ...    ...                  ...   \n","53106  EXIST2021_training    0.0                  NaN   \n","53107  EXIST2021_training    0.0                  NaN   \n","53108  EXIST2021_training    0.0                  NaN   \n","53109  EXIST2021_training    1.0                  NaN   \n","53110  EXIST2021_training    1.0                  NaN   \n","\n","                                                    text  \\\n","49598  Nadie te va a tratar tan bien como un hombre q...   \n","49599  @lindagisela74 Que rica putita obediente, afor...   \n","49600  @BicireporteraDF Yo lo hice a los 18 a√±os por ...   \n","49601  las cosas q sue√±o son indicios de que yo enrea...   \n","49602  Pero a la ni√±a le gust√≥ desde que lo vi√≥, as√≠ ...   \n","...                                                  ...   \n","53106  Estamos igual sin pareja, pero puedes besar a ...   \n","53107                          2020 hijo de re mil putas   \n","53108  SEGURAMENTE ESTA CHICA NO COBRA EL DINERO QUE ...   \n","53109     @safetyaitana mi madre dice q va fea y i agree   \n","53110  ¬øEn vuestras casas tambi√©n ten√©is esa tradici√≥...   \n","\n","                                            text_english      id  \\\n","49598  No one is going to treat you as well as a man ...  3437.0   \n","49599  @lindagisela74 What a delicious obedient littl...  3438.0   \n","49600  @BicireporteraDF I did it when I was 18 on the...  3439.0   \n","49601  The things I dream are indications that I am a...  3440.0   \n","49602  But the girl liked him from the moment she saw...  3441.0   \n","...                                                  ...     ...   \n","53106  We're the same without a partner, but you can ...  6973.0   \n","53107                                2020 son of a bitch  6974.0   \n","53108  SURELY THIS GIRL DOESN'T GET PAID THE MONEY SH...  6975.0   \n","53109  @safetyaitana my mother says she looks ugly an...  6976.0   \n","53110  Do you also have that shitty tradition in your...  6977.0   \n","\n","      subcategory_general subcategory_specific rewire_id label_sexist  ...  \\\n","49598                 NaN                  NaN       NaN          NaN  ...   \n","49599                 NaN                  NaN       NaN          NaN  ...   \n","49600                 NaN                  NaN       NaN          NaN  ...   \n","49601                 NaN                  NaN       NaN          NaN  ...   \n","49602                 NaN                  NaN       NaN          NaN  ...   \n","...                   ...                  ...       ...          ...  ...   \n","53106                 NaN                  NaN       NaN          NaN  ...   \n","53107                 NaN                  NaN       NaN          NaN  ...   \n","53108                 NaN                  NaN       NaN          NaN  ...   \n","53109                 NaN                  NaN       NaN          NaN  ...   \n","53110                 NaN                  NaN       NaN          NaN  ...   \n","\n","      annotator  HS  TR  AG  original_label  test_case   source  language  \\\n","49598       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","49599       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","49600       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","49601       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","49602       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","...         ...  ..  ..  ..             ...        ...      ...       ...   \n","53106       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","53107       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","53108       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","53109       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","53110       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","\n","            task1                   task2  \n","49598      sexist         sexual-violence  \n","49599      sexist  stereotyping-dominance  \n","49600  non-sexist              non-sexist  \n","49601  non-sexist              non-sexist  \n","49602  non-sexist              non-sexist  \n","...           ...                     ...  \n","53106  non-sexist              non-sexist  \n","53107  non-sexist              non-sexist  \n","53108  non-sexist              non-sexist  \n","53109      sexist         objectification  \n","53110      sexist  stereotyping-dominance  \n","\n","[3513 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-252cf7f7-3c16-4551-b241-29aadc3e6935\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_dataset</th>\n","      <th>label</th>\n","      <th>subcategory_combined</th>\n","      <th>text</th>\n","      <th>text_english</th>\n","      <th>id</th>\n","      <th>subcategory_general</th>\n","      <th>subcategory_specific</th>\n","      <th>rewire_id</th>\n","      <th>label_sexist</th>\n","      <th>...</th>\n","      <th>annotator</th>\n","      <th>HS</th>\n","      <th>TR</th>\n","      <th>AG</th>\n","      <th>original_label</th>\n","      <th>test_case</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49598</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>Nadie te va a tratar tan bien como un hombre q...</td>\n","      <td>No one is going to treat you as well as a man ...</td>\n","      <td>3437.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>sexual-violence</td>\n","    </tr>\n","    <tr>\n","      <th>49599</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>@lindagisela74 Que rica putita obediente, afor...</td>\n","      <td>@lindagisela74 What a delicious obedient littl...</td>\n","      <td>3438.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>stereotyping-dominance</td>\n","    </tr>\n","    <tr>\n","      <th>49600</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>@BicireporteraDF Yo lo hice a los 18 a√±os por ...</td>\n","      <td>@BicireporteraDF I did it when I was 18 on the...</td>\n","      <td>3439.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>49601</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>las cosas q sue√±o son indicios de que yo enrea...</td>\n","      <td>The things I dream are indications that I am a...</td>\n","      <td>3440.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>49602</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>Pero a la ni√±a le gust√≥ desde que lo vi√≥, as√≠ ...</td>\n","      <td>But the girl liked him from the moment she saw...</td>\n","      <td>3441.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>53106</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>Estamos igual sin pareja, pero puedes besar a ...</td>\n","      <td>We're the same without a partner, but you can ...</td>\n","      <td>6973.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>53107</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>2020 hijo de re mil putas</td>\n","      <td>2020 son of a bitch</td>\n","      <td>6974.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>53108</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>SEGURAMENTE ESTA CHICA NO COBRA EL DINERO QUE ...</td>\n","      <td>SURELY THIS GIRL DOESN'T GET PAID THE MONEY SH...</td>\n","      <td>6975.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>53109</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>@safetyaitana mi madre dice q va fea y i agree</td>\n","      <td>@safetyaitana my mother says she looks ugly an...</td>\n","      <td>6976.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","    </tr>\n","    <tr>\n","      <th>53110</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>¬øEn vuestras casas tambi√©n ten√©is esa tradici√≥...</td>\n","      <td>Do you also have that shitty tradition in your...</td>\n","      <td>6977.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>stereotyping-dominance</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3513 rows √ó 24 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-252cf7f7-3c16-4551-b241-29aadc3e6935')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-252cf7f7-3c16-4551-b241-29aadc3e6935 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-252cf7f7-3c16-4551-b241-29aadc3e6935');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-36be1464-6839-48b0-a724-a702e49e6db7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36be1464-6839-48b0-a724-a702e49e6db7')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-36be1464-6839-48b0-a724-a702e49e6db7 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_6b1500ae-1fe9-46d6-941e-e00a4a4ba3fd\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_es')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_6b1500ae-1fe9-46d6-941e-e00a4a4ba3fd button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data_es');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data_es"}},"metadata":{},"execution_count":9}],"source":["data_es"]},{"cell_type":"code","execution_count":10,"id":"df3a1ba1","metadata":{"id":"df3a1ba1","executionInfo":{"status":"ok","timestamp":1751612232649,"user_tz":-120,"elapsed":7,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["# Fijamos la proporci√≥n deseada total (por ejemplo, 2000 muestras en total)\n","total_samples = 1000\n","samples_per_class = total_samples // 2  # 500 de cada clase\n","\n","# Filtramos por clase\n","data_0 = data_es[data_es['label'] == 0].sample(n=samples_per_class, random_state=42)\n","data_1 = data_es[data_es['label'] == 1].sample(n=samples_per_class, random_state=42)\n","\n","# Concatenamos y mezclamos\n","data_balanced = pd.concat([data_0, data_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":11,"id":"709b80e1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":947},"id":"709b80e1","executionInfo":{"status":"ok","timestamp":1751612232670,"user_tz":-120,"elapsed":16,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}},"outputId":"b55027cf-17f0-41c7-ddf8-d51db81f7954"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         source_dataset  label subcategory_combined  \\\n","0    EXIST2021_training    1.0                  NaN   \n","1    EXIST2021_training    1.0                  NaN   \n","2    EXIST2021_training    1.0                  NaN   \n","3    EXIST2021_training    1.0                  NaN   \n","4    EXIST2021_training    0.0                  NaN   \n","..                  ...    ...                  ...   \n","995  EXIST2021_training    0.0                  NaN   \n","996  EXIST2021_training    0.0                  NaN   \n","997  EXIST2021_training    1.0                  NaN   \n","998  EXIST2021_training    0.0                  NaN   \n","999  EXIST2021_training    0.0                  NaN   \n","\n","                                                  text  \\\n","0    ...(sigo)Siempre trata de un triangulo amoroso...   \n","1    @JoseantTf @SerranoIsmael Con esa misma puta m...   \n","2    AHORA LO PENS√âpero no seria mejor no utero no ...   \n","3    En la inmensa mayor√≠a de los homicidios de muj...   \n","4    que te conteste una se√±orita del directorio de...   \n","..                                                 ...   \n","995  si eso ya subid una foto de su polla https://t...   \n","996           @Lady_Don_gi masculinismo te lo presento   \n","997  @IrynaReborn Sin duda las rusas son las mujere...   \n","998  Saben qui√©n me cae mal? Mi cu√±ada. Saben qui√©n...   \n","999  @paulyn1979_ @subterfugia Se podr√≠a legalizar ...   \n","\n","                                          text_english      id  \\\n","0    ...(continued) It always deals with a love tri...  4820.0   \n","1    @JoseantTf @SerranoIsmael With that same fucki...  5267.0   \n","2    NOW I THOUGHT ABOUT IT but wouldn't it be bett...  6365.0   \n","3    In the vast majority of homicides of women by ...  6897.0   \n","4    Having a lady from the university's board answ...  6706.0   \n","..                                                 ...     ...   \n","995  If so, upload a photo of his cock https://t.co...  6186.0   \n","996          @Lady_Don_gi masculinism I present to you  6600.0   \n","997  @IrynaReborn Without a doubt, Russian women ar...  5688.0   \n","998  Do you know who I don't like? My sister-in-law...  5005.0   \n","999  @paulyn1979_ @subterfugia The murderer's decis...  4690.0   \n","\n","    subcategory_general subcategory_specific rewire_id label_sexist  ...  \\\n","0                   NaN                  NaN       NaN          NaN  ...   \n","1                   NaN                  NaN       NaN          NaN  ...   \n","2                   NaN                  NaN       NaN          NaN  ...   \n","3                   NaN                  NaN       NaN          NaN  ...   \n","4                   NaN                  NaN       NaN          NaN  ...   \n","..                  ...                  ...       ...          ...  ...   \n","995                 NaN                  NaN       NaN          NaN  ...   \n","996                 NaN                  NaN       NaN          NaN  ...   \n","997                 NaN                  NaN       NaN          NaN  ...   \n","998                 NaN                  NaN       NaN          NaN  ...   \n","999                 NaN                  NaN       NaN          NaN  ...   \n","\n","    annotator  HS  TR  AG  original_label  test_case   source  language  \\\n","0         NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","1         NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","2         NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","3         NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","4         NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","..        ...  ..  ..  ..             ...        ...      ...       ...   \n","995       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","996       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","997       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","998       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","999       NaN NaN NaN NaN             NaN  EXIST2021  twitter        es   \n","\n","          task1                         task2  \n","0        sexist               objectification  \n","1        sexist  misogyny-non-sexual-violence  \n","2        sexist        ideological-inequality  \n","3        sexist  misogyny-non-sexual-violence  \n","4    non-sexist                    non-sexist  \n","..          ...                           ...  \n","995  non-sexist                    non-sexist  \n","996  non-sexist                    non-sexist  \n","997      sexist        stereotyping-dominance  \n","998  non-sexist                    non-sexist  \n","999  non-sexist                    non-sexist  \n","\n","[1000 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-38247515-981e-4d89-a52e-704fd59ff0fe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_dataset</th>\n","      <th>label</th>\n","      <th>subcategory_combined</th>\n","      <th>text</th>\n","      <th>text_english</th>\n","      <th>id</th>\n","      <th>subcategory_general</th>\n","      <th>subcategory_specific</th>\n","      <th>rewire_id</th>\n","      <th>label_sexist</th>\n","      <th>...</th>\n","      <th>annotator</th>\n","      <th>HS</th>\n","      <th>TR</th>\n","      <th>AG</th>\n","      <th>original_label</th>\n","      <th>test_case</th>\n","      <th>source</th>\n","      <th>language</th>\n","      <th>task1</th>\n","      <th>task2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>...(sigo)Siempre trata de un triangulo amoroso...</td>\n","      <td>...(continued) It always deals with a love tri...</td>\n","      <td>4820.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>objectification</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>@JoseantTf @SerranoIsmael Con esa misma puta m...</td>\n","      <td>@JoseantTf @SerranoIsmael With that same fucki...</td>\n","      <td>5267.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>misogyny-non-sexual-violence</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>AHORA LO PENS√âpero no seria mejor no utero no ...</td>\n","      <td>NOW I THOUGHT ABOUT IT but wouldn't it be bett...</td>\n","      <td>6365.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>ideological-inequality</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>En la inmensa mayor√≠a de los homicidios de muj...</td>\n","      <td>In the vast majority of homicides of women by ...</td>\n","      <td>6897.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>misogyny-non-sexual-violence</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>que te conteste una se√±orita del directorio de...</td>\n","      <td>Having a lady from the university's board answ...</td>\n","      <td>6706.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>si eso ya subid una foto de su polla https://t...</td>\n","      <td>If so, upload a photo of his cock https://t.co...</td>\n","      <td>6186.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>@Lady_Don_gi masculinismo te lo presento</td>\n","      <td>@Lady_Don_gi masculinism I present to you</td>\n","      <td>6600.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>EXIST2021_training</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>@IrynaReborn Sin duda las rusas son las mujere...</td>\n","      <td>@IrynaReborn Without a doubt, Russian women ar...</td>\n","      <td>5688.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>sexist</td>\n","      <td>stereotyping-dominance</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>Saben qui√©n me cae mal? Mi cu√±ada. Saben qui√©n...</td>\n","      <td>Do you know who I don't like? My sister-in-law...</td>\n","      <td>5005.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>EXIST2021_training</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>@paulyn1979_ @subterfugia Se podr√≠a legalizar ...</td>\n","      <td>@paulyn1979_ @subterfugia The murderer's decis...</td>\n","      <td>4690.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EXIST2021</td>\n","      <td>twitter</td>\n","      <td>es</td>\n","      <td>non-sexist</td>\n","      <td>non-sexist</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows √ó 24 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38247515-981e-4d89-a52e-704fd59ff0fe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-38247515-981e-4d89-a52e-704fd59ff0fe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-38247515-981e-4d89-a52e-704fd59ff0fe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-144e0a8a-fc7a-4a43-bc0b-876fad825fb6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-144e0a8a-fc7a-4a43-bc0b-876fad825fb6')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-144e0a8a-fc7a-4a43-bc0b-876fad825fb6 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_f1f9e7ba-42e6-4ffa-8dcd-50b711252add\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_balanced')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f1f9e7ba-42e6-4ffa-8dcd-50b711252add button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data_balanced');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data_balanced"}},"metadata":{},"execution_count":11}],"source":["data_balanced"]},{"cell_type":"code","execution_count":12,"id":"5da962e3","metadata":{"id":"5da962e3","executionInfo":{"status":"ok","timestamp":1751612232685,"user_tz":-120,"elapsed":5,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["data_es = data_balanced.copy()"]},{"cell_type":"code","execution_count":13,"id":"485b9748-005e-4148-b59a-989b03483aab","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["61d480a58d0d41c297585aff41695861","cb043d5dd843450cbdc6f758a5425159","761a5cbd2ec643d392231e226b6f5048","9ad1b4d0eb334576b23552055a6cd6e3","777e45837cfd4ec4b31548c07c3788f0","df4ebe202833413d88fe465ef30b2697","0a457517f4ae42ea9f19ded6e587542e","cb932b3ffd344addb74000dafdb4cd51","fbec546f484a4b93a10cb4a84ab68d8f","3af5c4e4ab5d46488e99f7369fa9b354","532c2fe80ed146848e3639d0242f6846","8e185d6ea2cf4df3a88633b982f06b4d","d322c45941ed4214a140e8877815dcdc","f69e0bd6481148eda8c08f5316b9bb96","bc6ece76f3f4491e865fa75df9a8f811","9526816e2462476aad0758df50155f85","1fa2d490d10a42439a9147025faedb52","2c4d4526b90d4eee86a5088316cdd0ec","5258d15d25874747b8abd59c99db6797","eaf03bef40e34a0dbdd63622fc75cbba","8d9366fc710b4e02ba3521a74a75bd70","23386fd966784a5893196ff3a7f292df","9935c9e4efe34df083a772e53ed2d093","38b167693d5542fc9ad395604fb10f23","bdd9842827f742b3ad1f9fe38b6d44be","5afb8faed14a4cd19f2a1f10477435ee","2afbc3d6cc77497fb90ea015a5d6615f","317366c5ce86461cba02aba34a34e9f9","9e3726123ea74ecc868443b8473f7b79","1dbdf3a76aae405d916d18d6756cd89b","8ca936d5fef0495e9aea53687e927258","8e085e0fdb4e421c8268a8e4316d7d4d","012b37514e5047c5b6ce71625424fd71"]},"id":"485b9748-005e-4148-b59a-989b03483aab","outputId":"4d47de7e-fb3e-4215-9204-be055aa58f0e","executionInfo":{"status":"ok","timestamp":1751612235050,"user_tz":-120,"elapsed":2360,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing dataset...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/681 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61d480a58d0d41c297585aff41695861"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/136 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e185d6ea2cf4df3a88633b982f06b4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/92 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9935c9e4efe34df083a772e53ed2d093"}},"metadata":{}}],"source":["#data_es = data.query(\"language == 'es'\")\n","sexism_data_es = SexismDataset(data_es,\n","                               task_name=\"detection\",\n","                               model_checkpoint=MODEL_CHECKPOINT)"]},{"cell_type":"markdown","id":"aea8b409-dbfb-4ca8-9e53-69138e4e2a3d","metadata":{"id":"aea8b409-dbfb-4ca8-9e53-69138e4e2a3d"},"source":["To further advance in our model development, we have implemented a crucial function called `train_transformer`. This function serves as the cornerstone for training our transformer-based models using tokenized datasets. By providing the necessary inputs, such as the fancy name for the training run, the tokenized dataset, the model name or path, the number of labels for the classification task, the tokenizer, and a function to compute evaluation metrics, we can efficiently train our models. Moreover, this function offers the flexibility to customize hyperparameters and choose whether to push the trained model to the Hugging Face model hub and evaluate its performance on the validation and test datasets. This powerful function streamlines the training process and enables us to iterate and refine our models effectively."]},{"cell_type":"code","execution_count":14,"id":"22aab4c9-547e-4e6d-8bf7-30a6589da5f0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"22aab4c9-547e-4e6d-8bf7-30a6589da5f0","executionInfo":{"status":"error","timestamp":1751612236366,"user_tz":-120,"elapsed":1312,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}},"outputId":"43916833-6519-4d8e-cf28-67d706e635c9"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_peft_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from .auto import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m from .peft_model import (\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDynamicCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoderDecoderCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuestionAnsweringModelOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-14-2566560718.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from transformers import ( \n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)"]}],"source":["from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments\n",")\n","#from api_setup import wandb_setup, huggingface_setup\n","\n","def train_transformer(\n","\n","    fancy_name: str,\n","    tokenized_dataset: Dataset,\n","    model_name: str,\n","    num_labels: int,\n","    tokenizer: AutoTokenizer,\n","    compute_metrics: Callable,\n","    hyper_params: dict = {},\n","    push_to_hub: bool = False,\n","    evaluate: bool = True\n","\n",") -> Trainer:\n","    \"\"\"\n","    Trains a transformer-based model using the provided tokenized dataset and hyperparameters.\n","\n","    Args:\n","        - fancy_name (str): A fancy name to identify the training run.\n","        - tokenized_dataset (datasets.Dataset): The tokenized dataset for training, validation, and testing.\n","        - model_name (str): The name or path of the pre-trained transformer model.\n","        - num_labels: The number of labels/classes for the classification task.\n","        - tokenizer (transformers.AutoTokenizer): The tokenizer for tokenizing the input sequences.\n","        - compute_metrics (Callable): A function to compute evaluation metrics.\n","        - hyper_params (dict, optional): Specific hyperparameters for training the model. Defaults to {}.\n","        - push_to_hub (bool, optional): Whether to push the trained model to the Hugging Face model hub. Defaults to False.\n","        - evaluate (bool, optional): Whether to evaluate the trained model on the validation and test datasets. Defaults to True.\n","\n","    Returns:\n","        Trainer: The trainer object used for training the model.\n","    \"\"\"\n","\n","    #if push_to_hub:\n","    #    huggingface_setup()\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        model_name, num_labels=num_labels\n","    )\n","\n","    # ‚ùÑÔ∏è Congelar las capas del modelo base (como Roberta, BERT, etc.)\n","    #for param in model.base_model.parameters():\n","     #   param.requires_grad = False\n","\n","    batch_size = hyper_params.get(\"batch_size\", 8)\n","    args = TrainingArguments(\n","        output_dir=fancy_name,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        learning_rate=hyper_params.get(\"lr\", 1.93009e-05),\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size,\n","        num_train_epochs=hyper_params.get(\"epochs\", 4),\n","        warmup_steps=hyper_params.get(\"warmup_steps\", 0),\n","        weight_decay=hyper_params.get(\"weight_decay\", 0.01),\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"f1\",\n","        push_to_hub=push_to_hub,\n","        max_steps=-1,\n","        logging_dir=\"./logs\",\n","        report_to=None\n","\n","    )\n","    \"\"\"\n","    args = TrainingArguments(\n","      output_dir=fancy_name,\n","      do_train=True,\n","      do_eval=True,\n","      save_steps=500,  # o cualquier valor razonable\n","      eval_steps=500,\n","      save_total_limit=1,\n","      learning_rate=hyper_params.get(\"lr\", 1.93009e-05),\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      num_train_epochs=hyper_params.get(\"epochs\", 4),\n","      warmup_steps=hyper_params.get(\"warmup_steps\", 0),\n","      weight_decay=hyper_params.get(\"weight_decay\", 0.01),\n","      load_best_model_at_end=True,\n","      max_steps=-1,\n","      logging_dir=\"./logs\",\n","      report_to=None  # o \"none\" si prefiere\n","    )\n","\n","    args = TrainingArguments(\n","      output_dir=fancy_name,\n","      do_train=True,\n","      do_eval=True,\n","      evaluation_strategy=\"steps\",  # ‚Üê aseg√∫rate de que esto est√© presente\n","      save_strategy=\"steps\",        # ‚Üê y este tambi√©n\n","      save_steps=500,\n","      eval_steps=500,\n","      load_best_model_at_end=True,\n","      learning_rate=hyper_params.get(\"lr\", 1.93009e-05),\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      num_train_epochs=hyper_params.get(\"epochs\", 4),\n","      warmup_steps=hyper_params.get(\"warmup_steps\", 0),\n","      weight_decay=hyper_params.get(\"weight_decay\", 0.01),\n","      logging_dir=\"./logs\",\n","      report_to=None\n","    )\"\"\"\n","\n","\n","    trainer = Trainer(\n","        model,\n","        args,\n","        train_dataset=tokenized_dataset[\"train\"],\n","        eval_dataset=tokenized_dataset[\"validation\"],\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics\n","    )\n","\n","    trainer.train()\n","\n","    if evaluate:\n","        print(\"\\nFinal model evaluation:\")\n","        trainer.evaluate()\n","        print(\"\\nResults over test data:\")\n","        preds = trainer.predict(tokenized_dataset[\"test\"])\n","        print(preds.metrics)\n","\n","    return trainer\n"]},{"cell_type":"markdown","id":"6c8e0509-11c7-4ca6-8e5e-445f65b2d86e","metadata":{"id":"6c8e0509-11c7-4ca6-8e5e-445f65b2d86e"},"source":["With the train_transformer function implemented, we proceeded to train our first approach for the Sexism Detection task using the original Spanish dataset. The function call was made, specifying the tokenized dataset, model name, number of labels, tokenizer, and evaluation metrics."]},{"cell_type":"code","execution_count":null,"id":"7bf1fb88","metadata":{"id":"7bf1fb88","executionInfo":{"status":"aborted","timestamp":1751612236570,"user_tz":-120,"elapsed":20,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["import os\n","os.environ[\"WANDB_MODE\"] = \"disabled\"\n"]},{"cell_type":"code","execution_count":null,"id":"d063c021","metadata":{"id":"d063c021","executionInfo":{"status":"aborted","timestamp":1751612236581,"user_tz":-120,"elapsed":3,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["sexism_data_es.num_labels == 2\n"]},{"cell_type":"code","execution_count":null,"id":"570e1431","metadata":{"id":"570e1431","executionInfo":{"status":"aborted","timestamp":1751612236588,"user_tz":-120,"elapsed":3,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["set(sexism_data_es.tokenized[\"train\"][\"label\"])\n","# deber√≠a ser {0, 1}\n","\n","\n"]},{"cell_type":"code","source":["load_best_model_at_end=False\n"],"metadata":{"id":"zl2Zx-wfKkA_","executionInfo":{"status":"aborted","timestamp":1751612236599,"user_tz":-120,"elapsed":3,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"id":"zl2Zx-wfKkA_","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"8fe1ba9b-9156-44ff-9583-94001276c386","metadata":{"id":"8fe1ba9b-9156-44ff-9583-94001276c386","executionInfo":{"status":"aborted","timestamp":1751612236614,"user_tz":-120,"elapsed":7,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["detector_trainer_es = train_transformer(fancy_name=\"unicc-josefina-sexism-detection-v0\",\n","                                        tokenized_dataset=sexism_data_es.tokenized,\n","                                        model_name=MODEL_CHECKPOINT,\n","                                        num_labels=sexism_data_es.num_labels,\n","                                        tokenizer=sexism_data_es.tokenizer,\n","                                        compute_metrics=sexism_data_es.build_compute_metrics(),\n","                                        evaluate=True,\n","                                        )"]},{"cell_type":"markdown","id":"57a36ccd-905e-4e87-b51a-ede6535984a0","metadata":{"id":"57a36ccd-905e-4e87-b51a-ede6535984a0"},"source":["The training process for the Sexism Detection model on the original Spanish dataset showed promising results. The model achieved an accuracy of approximately 78.7% and an F1 score of around 0.78. These metrics indicate a good performance in identifying instances of sexism. The evaluation on the test data also yielded similar results, with an accuracy of 78.2% and an F1 score of 0.77. These outcomes demonstrate the model's effectiveness in detecting sexism in the Spanish language."]},{"cell_type":"code","execution_count":null,"id":"397091e8-317d-4783-bdbd-6dff0036ca74","metadata":{"id":"397091e8-317d-4783-bdbd-6dff0036ca74","executionInfo":{"status":"aborted","timestamp":1751612236620,"user_tz":-120,"elapsed":79426,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["detector_trainer_es.save_model(\"../src3/detector/josefina-sexism-detection-v0\")"]},{"cell_type":"markdown","id":"5b8f2ed9-54a1-48a2-8a33-ae0bb3ad718a","metadata":{"tags":[],"id":"5b8f2ed9-54a1-48a2-8a33-ae0bb3ad718a"},"source":["### Training with Also Translated data"]},{"cell_type":"markdown","id":"024b6c2a-f9f4-4aef-bcde-726776e9dc95","metadata":{"id":"024b6c2a-f9f4-4aef-bcde-726776e9dc95"},"source":["Continuing with the training process, we now proceed with the second approach, which involves using translated data. The dataset consists of instances translatef from English to Mexican Spanish. We initialize the SexismDataset object with this translated data and then call the train_transformer function to train the model. This allows us to leverage the power of pre-trained language models and fine-tune them on the translated dataset. The evaluation results will shed light on the model's performance in detecting sexism in various languages."]},{"cell_type":"code","execution_count":null,"id":"b8a271e1-6952-4779-92f1-a3606aaabb43","metadata":{"id":"b8a271e1-6952-4779-92f1-a3606aaabb43","executionInfo":{"status":"aborted","timestamp":1751612236625,"user_tz":-120,"elapsed":79423,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["full_data = data.query(\"language != 'en'\")\n","sexism_data = SexismDataset(full_data,\n","                            task_name=\"detection\",\n","                            model_checkpoint=MODEL_CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"id":"c42f4406-75fd-4b06-8649-4fff029fd464","metadata":{"id":"c42f4406-75fd-4b06-8649-4fff029fd464","executionInfo":{"status":"aborted","timestamp":1751612236717,"user_tz":-120,"elapsed":19,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["detector_trainer = train_transformer(fancy_name=\"unicc-josefina-sexism-detection\",\n","                                     tokenized_dataset=sexism_data.tokenized,\n","                                     model_name=MODEL_CHECKPOINT,\n","                                     num_labels=sexism_data.num_labels,\n","                                     tokenizer=sexism_data.tokenizer,\n","                                     compute_metrics=sexism_data.build_compute_metrics()\n","                                     evaluate=True,\n","                                     hyper_params={\"batch\":10})"]},{"cell_type":"markdown","id":"215ae82e-36f3-42a1-8b84-508f413a86c7","metadata":{"id":"215ae82e-36f3-42a1-8b84-508f413a86c7"},"source":["In comparing the model trained with translated data to the model trained with only original Spanish data, we observed notable improvements in various performance metrics. The F1 score of the translated data model reached 0.790, surpassing the F1 score of 0.751 achieved by the original Spanish model. This enhancement signifies the model's increased ability to effectively capture instances of sexism when trained on a more diverse dataset that includes translated instances. Moreover, the precision score of the translated data model improved to 0.751, indicating a higher level of accuracy in identifying positive instances compared to the original Spanish model. The recall score also increased to 0.819, indicating an enhanced capability to capture a greater proportion of actual positive instances. These results highlight the value of incorporating translated data to improve the overall performance and robustness of the sexism detection model."]},{"cell_type":"markdown","id":"69e36c79-fc0e-4229-8fa1-baf8f4b64c8e","metadata":{"tags":[],"id":"69e36c79-fc0e-4229-8fa1-baf8f4b64c8e"},"source":["### Hyperparameter Search with Population-Based Training\n","\n","In this subsection, we perform a hyperparameter search using a technique called Population-Based Training (PBT). The goal is to find optimal hyperparameters for training a transformer model. The hp_tune_transformer function is used for this purpose, and it leverages the Ray Tune library to perform the hyperparameter search.\n","\n","> ##### Population-Based Training (PBT)\n",">PBT is an optimization technique that combines population-based optimization with asynchronous hyperparameter tuning. It starts by sampling a population of hyperparameter configurations, and each configuration is trained and evaluated on a subset of the data. Based on their performance, the best configurations are identified and their hyperparameters are mutated and re-evaluated in subsequent iterations. This process of mutation and evaluation helps refine the hyperparameters over time, leading to improved performance."]},{"cell_type":"markdown","id":"d8e7f3a5-2e1d-4e3e-a4b9-197f1a5fd41c","metadata":{"id":"d8e7f3a5-2e1d-4e3e-a4b9-197f1a5fd41c"},"source":["The `hp_tune_transformer` function is a versatile tool for hyperparameter search using the Population-Based Training (PBT) strategy. It enables efficient exploration of the hyperparameter space to discover the optimal configuration for training a transformer model. This function leverages the Ray Tune library to perform iterative training and evaluation with various hyperparameter configurations, iteratively refining the parameters to improve model performance. With inputs such as the model name, tokenized dataset, tokenizer, and evaluation metrics, it supports reporting, logging, and saving the best hyperparameters and model. By using hp_tune_transformer, you can automate hyperparameter search and effectively enhance the performance of your transformer models. Is allows reporting to Weigths & Biases"]},{"cell_type":"code","execution_count":null,"id":"bcd40168-1554-44ca-bede-38a3a1845bd1","metadata":{"tags":[],"id":"bcd40168-1554-44ca-bede-38a3a1845bd1","executionInfo":{"status":"aborted","timestamp":1751612236721,"user_tz":-120,"elapsed":21,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["import ray\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import PopulationBasedTraining\n","\n","#from api_setup import wandb_setup\n","#from misc import save_json\n","\n","def get_setup_keys(*keys):\n","    aux, _suggest = {}, False\n","    for key in keys:\n","        value = os.getenv(key)\n","        if value is None:\n","            value = input(f\"Enter your `{key}`: \")\n","            _suggest = True\n","        aux[key] = value\n","    if _suggest:\n","        print(\"\\nConsider setting keys in system environ to not\" \\\n","              \"\\nenter them each time setting up is required.\\n\")\n","    return aux\n","\n","def wandb_setup(project_name):\n","    import wandb\n","    #wandb.login()\n","    key = get_setup_keys(\"WANDB_API_KEY\")\n","    os.environ[\"WANDB_API_KEY\"] = key[\"WANDB_API_KEY\"]\n","    # set the wandb project where this run will be logged\n","    os.environ[\"WANDB_PROJECT\"] = project_name\n","    # save your trained model checkpoint to wandb\n","    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n","    # turn off watch to log faster\n","    os.environ[\"WANDB_WATCH\"] = \"false\"\n","    wandb.init()\n","\n","def save_json(dict_, path):\n","    with open(path, mode='w+', encoding='utf-8') as f:\n","        json.dump(dict_, f, ensure_ascii=False, indent=4)\n","\n","def hp_tune_transformer(\n","        fancy_name: str,\n","        model_name: str,\n","        tokenized_dataset: Dataset,\n","        num_labels: int,\n","        tokenizer: AutoTokenizer,\n","        compute_metrics: Callable,\n","        num_samples: int = 8,\n","        cpus_per_trial: int = 1,\n","        gpus_per_trial: int = 0,\n","        report_to: Optional[str] = None,\n","        save_best_model: bool = False,\n","        smoke_test: bool = False\n","    ):\n","    \"\"\"\n","    Perform hyperparameter search using Population-Based Training (PBT) to find optimal hyperparameters\n","    for training a transformer model.\n","\n","    Args:\n","        - fancy_name (str): Name for the fancy experiment.\n","        - model_name (str): Name or path of the pre-trained transformer model.\n","        - tokenized_dataset (Dataset): Tokenized dataset containing train, validation, and test splits.\n","        - num_labels (int): Number of labels/classes in the dataset.\n","        - tokenizer (AutoTokenizer): Tokenizer for the transformer model.\n","        - compute_metrics (Callable): Function to compute evaluation metrics.\n","        - num_samples (int, optional): Number of hyperparameter samples to try. Defaults to 8.\n","        - cpus_per_trial (int, optional): Number of CPUs to allocate per trial. Defaults to 1.\n","        - gpus_per_trial (int, optional): Number of GPUs to allocate per trial. Defaults to 0.\n","        - report_to (Optional[str], optional): Reporting destination (e.g., 'wandb' for Weights & Biases).\n","                                               Defaults to None.\n","        - save_best_model (bool, optional): Whether to save the best model. Defaults to False.\n","        - smoke_test (bool, optional): Whether to perform a smoke test. Defaults to False.\n","\n","    Returns:\n","        BestRun: The best hyperparameter run.\n","    \"\"\"\n","    print(\"\\nSTARTING HYPER-PARAMETER SEARCH\")\n","    print(\"\\nDownloading and caching pre-trained model\")\n","    model_config = AutoConfig.from_pretrained(\n","        model_name, num_labels=num_labels\n","    )\n","\n","    # Triggers model download to cache\n","    AutoModelForSequenceClassification.from_pretrained(\n","        model_name, config=model_config,\n","    )\n","\n","    def get_model():\n","        return AutoModelForSequenceClassification.from_pretrained(\n","            model_name, config=model_config,\n","        )\n","\n","    # Sets training and hyperparameter search configuration\n","    training_args = TrainingArguments(\n","        output_dir=fancy_name,\n","        learning_rate=1e-5,  # config\n","        do_train=True,\n","        do_eval=True,\n","        no_cuda=gpus_per_trial <= 0,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        load_best_model_at_end=True,\n","        num_train_epochs=2,  # config\n","        max_steps=-1,\n","        per_device_train_batch_size=16,  # config\n","        per_device_eval_batch_size=16,  # config\n","        warmup_steps=0,  # config\n","        weight_decay=0.01,  # config\n","        logging_dir=\"./logs\",\n","        skip_memory_metrics=True,\n","        report_to=report_to\n","    )\n","\n","    trainer = Trainer(\n","        model_init=get_model,\n","        args=training_args,\n","        tokenizer=tokenizer,\n","        train_dataset=tokenized_dataset[\"train\"],\n","        eval_dataset=tokenized_dataset[\"validation\"],\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    tune_config = {\n","        \"per_device_train_batch_size\": tune.choice([8, 16, 32, 64]),\n","        \"per_device_eval_batch_size\": tune.choice([8, 16, 32, 64]),\n","        \"num_train_epochs\": tune.choice([2, 3, 4, 5]),\n","        \"max_steps\": 1 if smoke_test else -1,  # Used for smoke test.\n","    }\n","\n","    scheduler = PopulationBasedTraining(\n","        time_attr=\"training_iteration\",\n","        metric=\"eval_f1\",\n","        mode=\"max\",\n","        perturbation_interval=1,\n","        hyperparam_mutations={\n","            \"learning_rate\": tune.uniform(1e-5, 1e-6),\n","            \"weight_decay\": tune.uniform(0.0, 0.5),\n","            \"warmup_steps\": tune.randint(0, 500),\n","            \"per_device_train_batch_size\":  tune.choice([8, 16, 32, 64]),\n","        },\n","    )\n","\n","    reporter = CLIReporter(\n","        parameter_columns={\n","            \"weight_decay\": \"w_decay\",\n","            \"warmup_steps\": \"warmup_steps\",\n","            \"learning_rate\": \"lr\",\n","            \"per_device_train_batch_size\": \"train_bs/gpu\",\n","            \"num_train_epochs\": \"num_epochs\",\n","        },\n","        metric_columns=[\n","            \"epoch\", \"training_iteration\", \"eval_loss\", \"eval_accuracy\",\n","            \"eval_f1\", \"eval_precision\", \"eval_recall\"\n","        ],\n","    )\n","\n","    ray.shutdown()\n","    ray.init(log_to_driver=True, ignore_reinit_error=True)\n","\n","    if report_to == \"wandb\":\n","        wandb_setup(project_name=fancy_name)\n","\n","    best_run = trainer.hyperparameter_search(\n","        hp_space=lambda _: tune_config,\n","        backend=\"ray\",\n","        n_trials=num_samples,\n","        resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n","        scheduler=scheduler,\n","        keep_checkpoints_num=1,\n","        checkpoint_score_attr=\"training_iteration\",\n","        stop={\"training_iteration\": 1} if smoke_test else None,\n","        progress_reporter=reporter,\n","        local_dir=\"ray_results/\",\n","        name=fancy_name + \"-tune_transformer_pbt\",\n","        log_to_file=not(bool(report_to)),\n","    )\n","\n","    print(\"\\nFinal model evaluation:\")\n","    best_run.evaluate()\n","    print(\"\\nResults over test data:\")\n","    preds = best_run.predict(tokenized_dataset[\"test\"])\n","    print(preds.metrics)\n","\n","    print(\"\\nSaving results...\")\n","    save_json(best_run.hyperparameters,\n","              path=fancy_name + \"-best_hyperparameters.json\")\n","\n","    if save_best_model:\n","        best_run.save_model(fancy_name + \"-model\")\n","\n","    return best_run"]},{"cell_type":"code","execution_count":null,"id":"8e632e2f-e26e-4f9b-b704-938822c5ba14","metadata":{"id":"8e632e2f-e26e-4f9b-b704-938822c5ba14","executionInfo":{"status":"aborted","timestamp":1751612236725,"user_tz":-120,"elapsed":18,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["sexism_data_sample = SexismDataset(full_data,\n","                                   task_name=\"detection\",\n","                                   model_checkpoint=MODEL_CHECKPOINT,\n","                                   max_instances=10000)\n","\n","fancy_name = \"\"\n","best_run = hp_tune_transformer(fancy_name=fancy_name,\n","                               model_name=MODEL_CHECKPOINT,\n","                               tokenized_dataset=sexism_data_sample.tokenized,\n","                               num_labels=sexism_data_sample.num_labels,\n","                               tokenizer=sexism_data_sample.tokenizer,\n","                               compute_metrics=sexism_data_sample.build_compute_metrics(),\n","                               num_samples=8,\n","                               cpus_per_trial=1,\n","                               gpus_per_trial=2,\n","                               report_to=\"wandb\")"]},{"cell_type":"code","execution_count":null,"id":"915a5609-37f4-46b0-925b-0c92110e60b7","metadata":{"id":"915a5609-37f4-46b0-925b-0c92110e60b7","executionInfo":{"status":"aborted","timestamp":1751612236731,"user_tz":-120,"elapsed":21,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["for n, v in best_run.hyperparameters.items():\n","    setattr(detector_trainer.args, n, v)\n","\n","detector_trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"dfab1a99-dce4-4460-96f6-24c5f76a485f","metadata":{"id":"dfab1a99-dce4-4460-96f6-24c5f76a485f","executionInfo":{"status":"aborted","timestamp":1751612236734,"user_tz":-120,"elapsed":21,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["detector_trainer.save_model(\"../src3/detector/josefina-sexism-detection-vf\")"]},{"cell_type":"markdown","id":"a2ef11c6-f1da-4d69-8128-b224c849b5f9","metadata":{"id":"a2ef11c6-f1da-4d69-8128-b224c849b5f9"},"source":["### Optimal Threshold"]},{"cell_type":"code","execution_count":null,"id":"9a90f49d-c645-4c38-9d24-cb0e06328349","metadata":{"id":"9a90f49d-c645-4c38-9d24-cb0e06328349","executionInfo":{"status":"aborted","timestamp":1751612236738,"user_tz":-120,"elapsed":23,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["a = [3,2,1]\n","a.sort(key=lambda x: x)\n","a"]},{"cell_type":"code","execution_count":null,"id":"6cd620fe-4a69-4699-b156-e503d1f6d4af","metadata":{"id":"6cd620fe-4a69-4699-b156-e503d1f6d4af","executionInfo":{"status":"aborted","timestamp":1751612236741,"user_tz":-120,"elapsed":79474,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["def predict_from_transformer(\n","        dataset: Dataset,\n","        checkpoint_or_path: str,\n","        mode: str = \"label\",\n","        local_files_only: bool = False,\n","        tokenizer_kwargs: dict = {}\n",") -> np.array:\n","    \"\"\"\n","    Performs inference using a pre-trained transformer model on a given dataset.\n","\n","    Args:\n","        - dataset (Dataset): The dataset to perform inference on. Must contain a \"text\" column.\n","        - checkpoint_or_path (str): The checkpoint or path to the pre-trained model.\n","        - mode (str, optional): The mode for prediction. Possible values are 'label' or 'proba'.\n","                                'label' returns the predicted label for each sample.\n","                                'proba' returns the predicted probabilities for each class.\n","                                 Defaults to 'label'.\n","        - local_files_only (bool, optional): Whether to only use local files when loading the model.\n","                                             Defaults to False.\n","        - tokenizer_kwargs (dict, optional): Additional keyword arguments to be passed to the tokenizer.\n","                                             Defaults to an empty dictionary.\n","\n","    Returns:\n","        numpy.array: An array of predicted labels or probabilities.\n","\n","    \"\"\"\n","    # Load the tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        checkpoint_or_path, local_files_only=local_files_only\n","    )\n","\n","    # Load the model\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        checkpoint_or_path, local_files_only=local_files_only\n","    )\n","\n","    # Create a text classification pipeline\n","    pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None)\n","\n","    preds = []\n","    for out in tqdm(pipe(KeyDataset(dataset, \"text\"), **tokenizer_kwargs)):\n","        if mode == \"label\":\n","            preds.append(out[0][\"label\"])  # Append the predicted label\n","        elif mode == \"proba\":\n","            out.sort(key=lambda x: x[\"label\"])\n","            preds.append([class_[\"score\"] for class_ in out])  # Append the predicted probabilities for each class\n","\n","    return np.array(preds)"]},{"cell_type":"code","execution_count":null,"id":"e38bd939-5820-4bc7-bb41-4c31fd3ac941","metadata":{"id":"e38bd939-5820-4bc7-bb41-4c31fd3ac941","executionInfo":{"status":"aborted","timestamp":1751612236746,"user_tz":-120,"elapsed":79472,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["model = \"../src3/detector/josefina-sexism-detection-vf\"\n","test_preds = predict_from_transformer(sexism_data.dataset[\"test\"],\n","                                      chekpoint_or_path=model,\n","                                      mode=\"proba\",\n","                                      local_files_only=True)"]},{"cell_type":"code","execution_count":null,"id":"88e7457c-35b5-4e48-9ea1-6727603370b2","metadata":{"id":"88e7457c-35b5-4e48-9ea1-6727603370b2","executionInfo":{"status":"aborted","timestamp":1751612236749,"user_tz":-120,"elapsed":79468,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","\n","def plot_binary_roc_curve(y, y_score):\n","    \"\"\"\n","    Plots the binary ROC curve based on the true labels and predicted scores.\n","\n","    Args:\n","        - y (array-like): The true labels.\n","        - y_score (array-like): The predicted scores.\n","\n","    \"\"\"\n","    # Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n","    fpr, tpr, thresholds = roc_curve(y, y_score)\n","\n","    # Create a plotly figure for the ROC curve\n","    fig = px.area(\n","        x=fpr, y=tpr,\n","        title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","        labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","        width=700, height=500\n","    )\n","\n","    # Add a diagonal line to the plot\n","    fig.add_shape(\n","        type='line', line=dict(dash='dash'),\n","        x0=0, x1=1, y0=0, y1=1\n","    )\n","\n","    # Compute the optimal threshold as the median of the true positive rate\n","    optimal_threshold = np.median(tpr)\n","    print(\"Best Threshold:\", optimal_threshold)\n","\n","    # Add a vertical line for the optimal threshold\n","    fig.add_shape(\n","        type='line', line=dict(dash='dash', color=\"red\"),\n","        x0=optimal_threshold, x1=optimal_threshold, y0=0, y1=1\n","    )\n","\n","    # Configure the plot axes\n","    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","    fig.update_xaxes(constrain='domain')\n","\n","    # Show the plot\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"id":"01097744-fa69-4640-ae02-8b7e6791b9f0","metadata":{"id":"01097744-fa69-4640-ae02-8b7e6791b9f0","executionInfo":{"status":"aborted","timestamp":1751612236755,"user_tz":-120,"elapsed":79466,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["plot_binary_roc_curve(\n","    y=np.array(sexism_data.dataset[\"test\"][\"label\"]),\n","    y_score=test_preds[:, 1]\n",")"]},{"cell_type":"markdown","id":"38bfc1d7-9b86-4a94-83bf-16f24bf8624e","metadata":{"tags":[],"id":"38bfc1d7-9b86-4a94-83bf-16f24bf8624e"},"source":["## Rosita - Sexism Classification"]},{"cell_type":"markdown","id":"3c68c5dc-7837-4dbf-baf2-ca35bb26324f","metadata":{"id":"3c68c5dc-7837-4dbf-baf2-ca35bb26324f"},"source":["Rosita is our specialized model designed for the classification of sexist content into different types. Built upon the ROBERTA-base-bne architecture, Rosita excels at accurately identifying and categorizing instances of sexism in text. It focuses on classifying sexist content into specific types, including \"violent,\" \"hate,\" \"profanities,\" \"abuse,\" and \"sexually-explicit\". In this section, we will dive into the features and performance of Rosita, highlighting its effectiveness in classifying and understanding different types of sexist content."]},{"cell_type":"markdown","id":"91ad5777-f21b-4947-b9b6-1ff5c808f750","metadata":{"tags":[],"id":"91ad5777-f21b-4947-b9b6-1ff5c808f750"},"source":["### Training with Original Spanish data"]},{"cell_type":"markdown","id":"f3e74151-498c-4553-ab9a-d0fb6caf3d6d","metadata":{"id":"f3e74151-498c-4553-ab9a-d0fb6caf3d6d"},"source":["In this subsection, we shift our focus to the original Spanish dataset. We analyze the performance of Rosita, the sexism classification model, on this dataset and proceed as with the previous model, but now calling the `SexismDataset` for the classification task."]},{"cell_type":"code","execution_count":null,"id":"3a42eea8-caa3-4aba-a321-8e5ccc8d42ca","metadata":{"id":"3a42eea8-caa3-4aba-a321-8e5ccc8d42ca","executionInfo":{"status":"aborted","timestamp":1751612236760,"user_tz":-120,"elapsed":79464,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["data_es_sexist = data_es.query(\"type != 'non-sexist'\")\n","sexism_data_es_sexist = SexismDataset(data_es_sexist,\n","                                      task_name=\"classification\",\n","                                      model_checkpoint=MODEL_CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"id":"4997ba69-1557-4ded-abd4-09d880e3f88d","metadata":{"id":"4997ba69-1557-4ded-abd4-09d880e3f88d","executionInfo":{"status":"aborted","timestamp":1751612236767,"user_tz":-120,"elapsed":2,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["tagger_trainer_es = train_transformer(fancy_name=\"unicc-rosita-sexism-classification-v0\",\n","                                      tokenized_dataset=sexism_data_es_sexist.tokenized,\n","                                      model_name=MODEL_CHECKPOINT,\n","                                      num_labels=sexism_data_es_sexist.num_labels,\n","                                      tokenizer=sexism_data_es_sexist.tokenizer,\n","                                      compute_metrics=sexism_data_es_sexist.build_compute_metrics()\n","                                      hyper_params={\"epochs\":6},\n","                                      evaluate=True)"]},{"cell_type":"markdown","id":"eb1aabef-1f01-4995-982a-8c4621204437","metadata":{"id":"eb1aabef-1f01-4995-982a-8c4621204437"},"source":["In the final evaluation, the model achieves an F1-score of 0.674, indicating a balanced trade-off between precision and recall. The precision value is 0.694, reflecting the model's ability to accurately classify instances of sexism, while the recall value of 0.661 suggests that the model captures a substantial portion of actual sexist instances.\n","\n","The results over the test data show a similar trend, with an F1-score of 0.622, precision of 0.631, and recall of 0.618. These metrics indicate that the model's performance generalizes reasonably well to unseen data, although there is a slight drop in performance compared to the validation set.\n","\n","Overall, the evaluation of Rosita on the original Spanish dataset highlights its effectiveness in classifying different types of sexism, as evidenced by the F1-score, precision, and recall metrics. However, further analysis and fine-tuning may be required to improve the model's performance and address any potential limitations."]},{"cell_type":"code","execution_count":null,"id":"198573f6-6ebc-4a05-870c-808ef21f3e72","metadata":{"id":"198573f6-6ebc-4a05-870c-808ef21f3e72","executionInfo":{"status":"aborted","timestamp":1751612236866,"user_tz":-120,"elapsed":95,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["tagger_trainer_es.save_model(\"../src3/tagger/rosita-sexism-classification-v0\")"]},{"cell_type":"markdown","id":"869c7402-128e-4d8c-a1f7-85eb19189516","metadata":{"tags":[],"id":"869c7402-128e-4d8c-a1f7-85eb19189516"},"source":["### Training with Also Translated data"]},{"cell_type":"markdown","id":"4f9033e3-6322-4055-a31e-2aa51a8d4e5c","metadata":{"id":"4f9033e3-6322-4055-a31e-2aa51a8d4e5c"},"source":["Now we evaluate the performance of Rosita on the translated data."]},{"cell_type":"code","execution_count":null,"id":"b14f9e2f-d7b4-4aac-93c8-c8a404a21aeb","metadata":{"id":"b14f9e2f-d7b4-4aac-93c8-c8a404a21aeb","executionInfo":{"status":"aborted","timestamp":1751612236872,"user_tz":-120,"elapsed":34,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["full_data_sexist = data.query(\"language!='en' and type!='non-sexist'\")\n","sexism_data_sexist = SexismDataset(full_data_sexist,\n","                                   task_name=\"classification\",\n","                                   model_checkpoint=MODEL_CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"id":"91ecba47-81a6-4082-9301-ba86ae354d2d","metadata":{"id":"91ecba47-81a6-4082-9301-ba86ae354d2d","executionInfo":{"status":"aborted","timestamp":1751612236878,"user_tz":-120,"elapsed":37,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["tagger_trainer = train_transformer(fancy_name=\"unicc-rosita-sexism-detection\",\n","                                   tokenized_dataset=sexism_data_sexist.tokenized,\n","                                   model_name=MODEL_CHECKPOINT,\n","                                   num_labels=sexism_data_sexist.num_labels,\n","                                   tokenizer=sexism_data_sexist.tokenizer,\n","                                   compute_metrics=sexism_data_sexist.build_compute_metrics()\n","                                   evaluate=True,\n","                                   hyper_params={\"batch\":10})"]},{"cell_type":"markdown","id":"ea6b6e4d-74f9-4c35-b896-95f406df0153","metadata":{"id":"ea6b6e4d-74f9-4c35-b896-95f406df0153"},"source":["In comparing the results between training and evaluating Rosita on the original Spanish dataset and incorporating translated and synthetic instances, we observed a slight decrease in performance in the second task. We hypothesize that this decrease could be attributed to the challenge of homogenizing the different label sets from each data source. The combination of diverse data sources made it difficult to separate similar labels into distinct categories.\n","\n","The merging of labels from different sources may have introduced some noise and ambiguity into the training process, resulting in a marginal decrease in the F1-score. It is possible that the overlapping or conflicting labels affected the model's ability to learn and generalize effectively across the different types of sexism.\n","\n","To further improve the performance of the classification model, future work could focus on refining the label assignment process and exploring techniques to handle label heterogeneity. By carefully addressing these challenges and finding ways to better integrate and reconcile the different label sets, we may be able to mitigate the potential noise and ambiguity introduced by the combination of translated and synthetic instances. This could lead to improved performance and a more accurate classification of sexism in Spanish text."]},{"cell_type":"markdown","id":"f1c9a335-b09c-4011-b796-3bcf13cbfb05","metadata":{"tags":[],"id":"f1c9a335-b09c-4011-b796-3bcf13cbfb05"},"source":["### Hyperparameter-tuning"]},{"cell_type":"code","execution_count":null,"id":"9f739c58-bd6e-444c-9f4e-0f09b3477ae3","metadata":{"id":"9f739c58-bd6e-444c-9f4e-0f09b3477ae3","executionInfo":{"status":"aborted","timestamp":1751612236884,"user_tz":-120,"elapsed":39,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["sexism_types_data_sample = SexismDataset(full_data_sexist,\n","                                         task_name=\"classification\",\n","                                         model_checkpoint=MODEL_CHECKPOINT,\n","                                         max_instances=10000)\n","\n","fancy_name = \"\"\n","best_run2 = hp_tune_transformer(fancy_name=fancy_name,\n","                                model_name=MODEL_CHECKPOINT,\n","                                tokenized_dataset=sexism_types_data_sample.tokenized,\n","                                num_labels=sexism_types_data_sample.num_labels,\n","                                tokenizer=sexism_types_data_sample.tokenizer,\n","                                compute_metrics=sexism_types_data_sample.build_compute_metrics(),\n","                                num_samples=8,\n","                                cpus_per_trial=1,\n","                                gpus_per_trial=2,\n","                                report_to=\"wandb\")"]},{"cell_type":"code","execution_count":null,"id":"a00e846e-ffaa-41f3-82db-b6cde6b89a6c","metadata":{"id":"a00e846e-ffaa-41f3-82db-b6cde6b89a6c","executionInfo":{"status":"aborted","timestamp":1751612236887,"user_tz":-120,"elapsed":40,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["for n, v in best_run2.hyperparameters.items():\n","    setattr(tagger_trainer.args, n, v)\n","\n","tagger_trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"324b4b3b-787f-404f-9df2-7e0f723a54da","metadata":{"id":"324b4b3b-787f-404f-9df2-7e0f723a54da","executionInfo":{"status":"aborted","timestamp":1751612236890,"user_tz":-120,"elapsed":40,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["tagger_trainer.save_model(\"../src3/detector/rosita-sexism-classification-vf\")"]},{"cell_type":"markdown","id":"819bab4a-a9da-41e9-bfe5-85f2c93666a5","metadata":{"id":"819bab4a-a9da-41e9-bfe5-85f2c93666a5"},"source":["### ROC Analysis"]},{"cell_type":"code","execution_count":null,"id":"e3268dec-72b7-4714-85ee-ec02637320dc","metadata":{"id":"e3268dec-72b7-4714-85ee-ec02637320dc","executionInfo":{"status":"aborted","timestamp":1751612236897,"user_tz":-120,"elapsed":44,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["# get the positive probabilities from the detector over the test set\n","model = \"../src3/detector/rosita-sexism-classification\"\n","test_preds2 = predict_from_transformer(sexism_data_sexist.dataset[\"test\"],\n","                                       chekpoint_or_path=model,\n","                                       mode=\"proba\",\n","                                       local_files_only=True)"]},{"cell_type":"code","execution_count":null,"id":"a02718e0-5328-4da5-8e0a-4ddab65039e7","metadata":{"id":"a02718e0-5328-4da5-8e0a-4ddab65039e7","executionInfo":{"status":"aborted","timestamp":1751612236901,"user_tz":-120,"elapsed":46,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["def plot_multiclass_roc_curve(y, y_score):\n","    \"\"\"\n","    Plots the Receiver Operating Characteristic (ROC) curve for multi-class classification.\n","\n","    Parameters:\n","    - y: True labels (array-like, shape [n_samples, n_classes])\n","    - y_score: Predicted scores (array-like, shape [n_samples, n_classes])\n","    \"\"\"\n","    # Compute ROC curve and ROC area for each class\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    for i in range(n_classes):\n","        fpr[i], tpr[i], _ = roc_curve(y[:, i], y_score[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    # Compute micro-average ROC curve and ROC area\n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_score.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","    # Compute macro-average ROC curve and ROC area\n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(n_classes):\n","        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= n_classes\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","    # Plot all ROC curves\n","    data = []\n","\n","    # Plot micro-average ROC curve\n","    trace1 = go.Scatter(\n","        x=fpr[\"micro\"],\n","        y=tpr[\"micro\"],\n","        mode='lines',\n","        line=dict(color='deeppink', width=lw, dash='dot'),\n","        name='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"])\n","    )\n","    data.append(trace1)\n","\n","    # Plot macro-average ROC curve\n","    trace2 = go.Scatter(\n","        x=fpr[\"macro\"],\n","        y=tpr[\"macro\"],\n","        mode='lines',\n","        line=dict(color='navy', width=lw, dash='dot'),\n","        name='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"])\n","    )\n","    data.append(trace2)\n","\n","    colors = cycle([\"#c4d454\", \"#a08c88\", \"#fbd305\", \"#EEC3B9\", \"#418fde\"])\n","    for i, color in zip(range(n_classes), colors):\n","        # Plot ROC curve for each class\n","        trace = go.Scatter(\n","            x=fpr[i],\n","            y=tpr[i],\n","            mode='lines',\n","            line=dict(color=color, width=lw),\n","            name='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i])\n","        )\n","        data.append(trace)\n","\n","    # Add a dashed line for reference\n","    trace4 = go.Scatter(\n","        x=[0, 1],\n","        y=[0, 1],\n","        mode='lines',\n","        line=dict(color='black', width=lw, dash='dash'),\n","        showlegend=False\n","    )\n","    data.append(trace4)\n","\n","    # Set layout for the plot\n","    layout = go.Layout(\n","        title='Some extension of Receiver operating characteristic to multi-class',\n","        xaxis=dict(title='False Positive Rate'),\n","        yaxis=dict(title='True Positive Rate')\n","    )\n","\n","    # Create the figure and display the plot\n","    fig = go.Figure(data=data, layout=layout)\n","    fig.show()\n"]},{"cell_type":"code","execution_count":null,"id":"7dec8cb0-21e4-4734-a135-ad919a8ba187","metadata":{"id":"7dec8cb0-21e4-4734-a135-ad919a8ba187","executionInfo":{"status":"aborted","timestamp":1751612236904,"user_tz":-120,"elapsed":46,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["plot_multiclass_roc_curve(\n","    y=OneHotEncoder().fit_transform(np.array(sexism_data_sexist.dataset[\"test\"][\"label\"]).reshape(-1, 1)).toarray(),\n","    y=label_binarize([0, 1, 2], classes=sexism_data_sexist.le.)\n","    y_score=test_preds2\n",")"]},{"cell_type":"markdown","id":"591352f5-e67e-4c45-9bf9-50163b728ce9","metadata":{"tags":[],"id":"591352f5-e67e-4c45-9bf9-50163b728ce9"},"source":["## Conclusions"]},{"cell_type":"markdown","id":"06f809b9-e356-4602-895d-c245b1a820b8","metadata":{"id":"06f809b9-e356-4602-895d-c245b1a820b8"},"source":["\n","Our experiments examined the performance of the models in the detection and classification tasks using both the Spanish dataset and the full dataset, which included translated and synthetic instances."]},{"cell_type":"code","execution_count":null,"id":"7a29285a-c07e-4b45-8082-5a56575cfcab","metadata":{"id":"7a29285a-c07e-4b45-8082-5a56575cfcab","executionInfo":{"status":"aborted","timestamp":1751612236912,"user_tz":-120,"elapsed":51,"user":{"displayName":"Juan Echeverri","userId":"00081912204900330630"}}},"outputs":[],"source":["idx = pd.MultiIndex.from_tuples([(\"detection\", \"spanish\"),\n","                           (\"detection\", \"translated\"),\n","                           (\"classification\", \"spanish\"),\n","                           (\"classification\", \"translated\")], names=[\"task\", \"dataset\"])\n","cols = pd.MultiIndex.from_tuples([(\"accuracy\", \"val\"),\n","                                  (\"accuracy\", \"test\"),\n","                                  (\"f1-score\", \"val\"),\n","                                  (\"f1-score\", \"test\"),\n","                                  (\"precision\", \"val\"),\n","                                  (\"precision\", \"test\"),\n","                                  (\"recall\", \"val\"),\n","                                  (\"recall\", \"test\")], names=[\"metric\", \"partition\"])\n","results = pd.DataFrame(data=[\n","    [ 0.787, 0.782, 0.782, 0.776, 0.725, 0.721, 0.848, 0.840 ],\n","    [ 0.801, 0.797, 0.790, 0.784, 0.751, 0.752, 0.834, 0.820 ],\n","    [ 0.685, 0.653, 0.674, 0.622, 0.694, 0.631, 0.661, 0.618 ],\n","    [ 0.679, 0.665, 0.602, 0.606, 0.641, 0.649, 0.581, 0.583 ]\n","], index=idx, columns=cols)\n","\n","res = results.melt(ignore_index=False).reset_index()\n","\n","fig = px.bar(\n","    res,\n","    x=\"metric\",\n","    y=\"value\",\n","    color=\"partition\",\n","    color_discrete_sequence = [BLUE2, RED],\n","    facet_col=\"task\",\n","    facet_row=\"dataset\",\n","    facet_row_spacing=0.1,\n","    facet_col_spacing=0.03,\n","    barmode=\"group\",\n","    range_y=(0.5, 0.9),\n","    text_auto='.2f',\n","    category_orders={\"task\": [\"detection\", \"classification\"]}\n",")\n","\n","fig.for_each_annotation(lambda a: a.update(text=\" \".join(reversed(a.text.split(\"=\"))).title()))\n","\n","fig.update_layout(\n","    autosize=False,\n","    width=700,\n","    height=600,)\n","fig.show()"]},{"cell_type":"markdown","id":"8b7ded86-8099-42f8-9151-7c40411fe731","metadata":{"id":"8b7ded86-8099-42f8-9151-7c40411fe731"},"source":["In the detection task, the model trained on the Spanish dataset achieved F1 scores of 0.782 on the validation set and 0.776 on the test set. However, when incorporating the translated and synthetic instances, the F1 scores notably improved to 0.790 on the validation set and 0.784 on the test set. These results demonstrate that including additional data sources did not compromise the model's performance but instead led to significant improvements in detecting the target content.\n","\n","In the classification task, the model trained on the Spanish dataset achieved F1 scores of 0.674 on the validation set and 0.622 on the test set. Upon incorporating the translated and synthetic instances, there was a slight decrease in the F1 scores, resulting in scores of 0.602 on the validation set and 0.606 on the test set. However, it is worth noting that the F1 scores remained relatively stable, indicating that the model's performance was not significantly impacted.\n","\n","We hypothesize that the decrease in the classification task may be attributed to the challenge of homogenizing label sets from different data sources, introducing noise and ambiguity during the training process. Future work could focus on refining the label assignment process and exploring techniques to handle label heterogeneity, potentially resulting in improved performance for the classification model.\n","\n","Overall, our experiments demonstrate the effectiveness of leveraging translated and synthetic instances to enhance the performance of the models. The inclusion of additional data sources led to notable improvements in the detection task and maintained relatively stable results in the classification task. These findings highlight the value of using large language models to obtain labeled instances for text classification in languages with limited labeled resources. By overcoming the limitations of scarce labeled data, this approach opens up new possibilities for applying artificial intelligence and machine learning in diverse linguistic contexts."]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"61d480a58d0d41c297585aff41695861":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb043d5dd843450cbdc6f758a5425159","IPY_MODEL_761a5cbd2ec643d392231e226b6f5048","IPY_MODEL_9ad1b4d0eb334576b23552055a6cd6e3"],"layout":"IPY_MODEL_777e45837cfd4ec4b31548c07c3788f0"}},"cb043d5dd843450cbdc6f758a5425159":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df4ebe202833413d88fe465ef30b2697","placeholder":"‚Äã","style":"IPY_MODEL_0a457517f4ae42ea9f19ded6e587542e","value":"Map:‚Äá100%"}},"761a5cbd2ec643d392231e226b6f5048":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb932b3ffd344addb74000dafdb4cd51","max":681,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbec546f484a4b93a10cb4a84ab68d8f","value":681}},"9ad1b4d0eb334576b23552055a6cd6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3af5c4e4ab5d46488e99f7369fa9b354","placeholder":"‚Äã","style":"IPY_MODEL_532c2fe80ed146848e3639d0242f6846","value":"‚Äá681/681‚Äá[00:00&lt;00:00,‚Äá1425.69‚Äáexamples/s]"}},"777e45837cfd4ec4b31548c07c3788f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df4ebe202833413d88fe465ef30b2697":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a457517f4ae42ea9f19ded6e587542e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb932b3ffd344addb74000dafdb4cd51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbec546f484a4b93a10cb4a84ab68d8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3af5c4e4ab5d46488e99f7369fa9b354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"532c2fe80ed146848e3639d0242f6846":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e185d6ea2cf4df3a88633b982f06b4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d322c45941ed4214a140e8877815dcdc","IPY_MODEL_f69e0bd6481148eda8c08f5316b9bb96","IPY_MODEL_bc6ece76f3f4491e865fa75df9a8f811"],"layout":"IPY_MODEL_9526816e2462476aad0758df50155f85"}},"d322c45941ed4214a140e8877815dcdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa2d490d10a42439a9147025faedb52","placeholder":"‚Äã","style":"IPY_MODEL_2c4d4526b90d4eee86a5088316cdd0ec","value":"Map:‚Äá100%"}},"f69e0bd6481148eda8c08f5316b9bb96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5258d15d25874747b8abd59c99db6797","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eaf03bef40e34a0dbdd63622fc75cbba","value":136}},"bc6ece76f3f4491e865fa75df9a8f811":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9366fc710b4e02ba3521a74a75bd70","placeholder":"‚Äã","style":"IPY_MODEL_23386fd966784a5893196ff3a7f292df","value":"‚Äá136/136‚Äá[00:00&lt;00:00,‚Äá1213.20‚Äáexamples/s]"}},"9526816e2462476aad0758df50155f85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa2d490d10a42439a9147025faedb52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c4d4526b90d4eee86a5088316cdd0ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5258d15d25874747b8abd59c99db6797":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf03bef40e34a0dbdd63622fc75cbba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d9366fc710b4e02ba3521a74a75bd70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23386fd966784a5893196ff3a7f292df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9935c9e4efe34df083a772e53ed2d093":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38b167693d5542fc9ad395604fb10f23","IPY_MODEL_bdd9842827f742b3ad1f9fe38b6d44be","IPY_MODEL_5afb8faed14a4cd19f2a1f10477435ee"],"layout":"IPY_MODEL_2afbc3d6cc77497fb90ea015a5d6615f"}},"38b167693d5542fc9ad395604fb10f23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_317366c5ce86461cba02aba34a34e9f9","placeholder":"‚Äã","style":"IPY_MODEL_9e3726123ea74ecc868443b8473f7b79","value":"Map:‚Äá100%"}},"bdd9842827f742b3ad1f9fe38b6d44be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dbdf3a76aae405d916d18d6756cd89b","max":92,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ca936d5fef0495e9aea53687e927258","value":92}},"5afb8faed14a4cd19f2a1f10477435ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e085e0fdb4e421c8268a8e4316d7d4d","placeholder":"‚Äã","style":"IPY_MODEL_012b37514e5047c5b6ce71625424fd71","value":"‚Äá92/92‚Äá[00:00&lt;00:00,‚Äá869.15‚Äáexamples/s]"}},"2afbc3d6cc77497fb90ea015a5d6615f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317366c5ce86461cba02aba34a34e9f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e3726123ea74ecc868443b8473f7b79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dbdf3a76aae405d916d18d6756cd89b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca936d5fef0495e9aea53687e927258":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e085e0fdb4e421c8268a8e4316d7d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"012b37514e5047c5b6ce71625424fd71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}